# 용어집

이러한 개념들은 Anthropic의 언어 모델에만 국한되지 않지만, 아래에 주요 용어들에 대한 간략한 요약을 제시합니다.

---

## 컨텍스트 윈도우

"컨텍스트 윈도우"는 언어 모델이 새로운 텍스트를 생성할 때 되돌아보고 참조할 수 있는 텍스트의 양을 의미합니다. 이는 언어 모델이 훈련된 대규모 데이터 코퍼스와는 다르며, 대신 모델의 "작업 메모리"를 나타냅니다. 더 큰 컨텍스트 윈도우는 모델이 더 복잡하고 긴 프롬프트를 이해하고 응답할 수 있게 하며, 더 작은 컨텍스트 윈도우는 모델이 더 긴 프롬프트를 처리하거나 확장된 대화에서 일관성을 유지하는 능력을 제한할 수 있습니다.

자세한 내용은 [컨텍스트 윈도우 이해 가이드](/docs/ko/build-with-claude/context-windows)를 참조하세요.

## 파인튜닝

파인튜닝은 추가 데이터를 사용하여 사전 훈련된 언어 모델을 추가로 훈련하는 과정입니다. 이는 모델이 파인튜닝 데이터셋의 패턴과 특성을 표현하고 모방하기 시작하게 합니다. Claude는 순수한 언어 모델이 아닙니다; 이미 도움이 되는 어시스턴트가 되도록 파인튜닝되었습니다. 저희 API는 현재 파인튜닝을 제공하지 않지만, 이 옵션을 탐색하는 데 관심이 있으시면 Anthropic 담당자에게 문의해 주세요. 파인튜닝은 언어 모델을 특정 도메인, 작업 또는 작성 스타일에 적응시키는 데 유용할 수 있지만, 파인튜닝 데이터와 모델의 성능 및 편향에 대한 잠재적 영향을 신중히 고려해야 합니다.

## HHH

이 세 개의 H는 Claude가 사회에 유익하도록 보장하는 Anthropic의 목표를 나타냅니다:

- **도움이 되는(helpful)** AI는 최선의 능력으로 주어진 작업을 수행하거나 질문에 답하려고 시도하며, 관련성 있고 유용한 정보를 제공합니다.
- **정직한(honest)** AI는 정확한 정보를 제공하며, 환각이나 허위 정보를 만들어내지 않습니다. 적절할 때 자신의 한계와 불확실성을 인정합니다.
- **무해한(harmless)** AI는 공격적이거나 차별적이지 않으며, 위험하거나 비윤리적인 행위를 도와달라는 요청을 받았을 때 정중히 거절하고 왜 응할 수 없는지 설명합니다.

## 지연시간

생성형 AI와 대규모 언어 모델의 맥락에서 지연시간은 모델이 주어진 프롬프트에 응답하는 데 걸리는 시간을 의미합니다. 프롬프트를 제출하고 생성된 출력을 받는 사이의 지연입니다. 낮은 지연시간은 더 빠른 응답 시간을 나타내며, 이는 실시간 애플리케이션, 챗봇, 상호작용 경험에 중요합니다. 지연시간에 영향을 줄 수 있는 요인으로는 모델 크기, 하드웨어 성능, 네트워크 조건, 프롬프트와 생성된 응답의 복잡성이 있습니다.

## LLM

대규모 언어 모델(LLM)은 많은 매개변수를 가진 AI 언어 모델로, 놀랍도록 유용한 다양한 작업을 수행할 수 있습니다. 이러한 모델들은 방대한 양의 텍스트 데이터로 훈련되며, 인간과 같은 텍스트를 생성하고, 질문에 답하고, 정보를 요약하는 등의 작업을 할 수 있습니다. Claude는 더 도움이 되고, 정직하고, 무해하도록 파인튜닝되고 RLHF를 사용하여 훈련된 대규모 언어 모델 기반의 대화형 어시스턴트입니다.

## MCP (Model Context Protocol)

Model Context Protocol(MCP)은 애플리케이션이 LLM에 컨텍스트를 제공하는 방법을 표준화하는 개방형 프로토콜입니다. AI 애플리케이션을 위한 USB-C 포트와 같이, MCP는 AI 모델을 다양한 데이터 소스와 도구에 연결하는 통합된 방법을 제공합니다. MCP는 AI 시스템이 상호작용 간에 일관된 컨텍스트를 유지하고 표준화된 방식으로 외부 리소스에 액세스할 수 있게 합니다. 자세한 내용은 [MCP 문서](/docs/ko/mcp)를 참조하세요.

## MCP 커넥터

MCP 커넥터는 API 사용자가 MCP 클라이언트를 구축하지 않고도 Messages API에서 직접 MCP 서버에 연결할 수 있게 하는 기능입니다. 이를 통해 Claude API를 통해 MCP 호환 도구 및 서비스와 원활하게 통합할 수 있습니다. MCP 커넥터는 도구 호출과 같은 기능을 지원하며 공개 베타로 제공됩니다. 자세한 내용은 [MCP 커넥터 문서](/docs/ko/agents-and-tools/mcp-connector)를 참조하세요.

## 사전훈련

사전훈련은 대규모 레이블이 없는 텍스트 코퍼스에서 언어 모델을 훈련하는 초기 과정입니다. Claude의 경우, 자기회귀 언어 모델(Claude의 기본 모델과 같은)은 문서의 이전 텍스트 컨텍스트가 주어졌을 때 다음 단어를 예측하도록 사전훈련됩니다. 이러한 사전훈련된 모델들은 본질적으로 질문에 답하거나 지시를 따르는 데 능숙하지 않으며, 원하는 행동을 이끌어내기 위해 종종 프롬프트 엔지니어링에 대한 깊은 기술이 필요합니다. 파인튜닝과 RLHF는 이러한 사전훈련된 모델들을 개선하여 광범위한 작업에 더 유용하게 만드는 데 사용됩니다.

## RAG (검색 증강 생성)

검색 증강 생성(RAG)은 정보 검색과 언어 모델 생성을 결합하여 생성된 텍스트의 정확성과 관련성을 향상시키고, 모델의 응답을 증거에 더 잘 근거하게 하는 기법입니다. RAG에서는 언어 모델이 컨텍스트 윈도우에 전달되는 외부 지식 베이스나 문서 세트로 증강됩니다. 데이터는 모델에 쿼리가 전송될 때 런타임에 검색되지만, 모델 자체가 반드시 데이터를 검색하는 것은 아닙니다([도구 사용](/docs/ko/agents-and-tools/tool-use/overview)과 검색 함수를 사용하면 가능합니다). 텍스트를 생성할 때, 먼저 입력 프롬프트를 기반으로 지식 베이스에서 관련 정보를 검색한 다음, 원래 쿼리와 함께 모델에 전달해야 합니다. 모델은 이 정보를 사용하여 생성하는 출력을 안내합니다. 이를 통해 모델이 훈련 데이터를 넘어서는 정보에 액세스하고 활용할 수 있어, 암기에 대한 의존도를 줄이고 생성된 텍스트의 사실적 정확성을 향상시킵니다. RAG는 최신 정보, 도메인별 지식 또는 명시적인 출처 인용이 필요한 작업에 특히 유용할 수 있습니다. 그러나 RAG의 효과는 외부 지식 베이스의 품질과 관련성, 그리고 런타임에 검색되는 지식에 따라 달라집니다.

## RLHF

인간 피드백을 통한 강화학습(RLHF)은 사전훈련된 언어 모델이 인간의 선호도와 일치하는 방식으로 행동하도록 훈련하는 데 사용되는 기법입니다. 여기에는 모델이 지시를 더 효과적으로 따르거나 챗봇처럼 행동하도록 돕는 것이 포함될 수 있습니다. 인간 피드백은 두 개 이상의 예시 텍스트 세트를 순위를 매기는 것으로 구성되며, 강화학습 과정은 모델이 더 높은 순위의 것과 유사한 출력을 선호하도록 장려합니다. Claude는 더 도움이 되는 어시스턴트가 되도록 RLHF를 사용하여 훈련되었습니다. 자세한 내용은 [이 주제에 대한 Anthropic의 논문](https://arxiv.org/abs/2204.05862)을 읽어보실 수 있습니다.

## 온도

온도는 텍스트 생성 중 모델 예측의 무작위성을 제어하는 매개변수입니다. 높은 온도는 더 창의적이고 다양한 출력을 만들어내며, 표현의 여러 변형과 소설의 경우 답변의 변형도 허용합니다. 낮은 온도는 가장 가능성 높은 표현과 답변에 충실한 더 보수적이고 결정론적인 출력을 만들어냅니다. 온도를 조정하면 사용자가 언어 모델이 가장 가능성 높은 예측만 선택하는 것이 아니라 드물고, 흔하지 않거나, 놀라운 단어 선택과 순서를 탐색하도록 장려할 수 있습니다.

## TTFT (첫 번째 토큰까지의 시간)

첫 번째 토큰까지의 시간(TTFT)은 언어 모델이 프롬프트를 받은 후 출력의 첫 번째 토큰을 생성하는 데 걸리는 시간을 측정하는 성능 지표입니다. 이는 모델의 반응성을 나타내는 중요한 지표이며, 사용자가 빠른 초기 피드백을 기대하는 상호작용 애플리케이션, 챗봇, 실시간 시스템에 특히 관련이 있습니다. 낮은 TTFT는 모델이 더 빠르게 응답 생성을 시작할 수 있음을 나타내며, 더 원활하고 매력적인 사용자 경험을 제공합니다. TTFT에 영향을 줄 수 있는 요인으로는 모델 크기, 하드웨어 성능, 네트워크 조건, 프롬프트의 복잡성이 있습니다.

## 토큰

토큰은 언어 모델의 가장 작은 개별 단위이며, 단어, 하위 단어, 문자, 또는 바이트(Unicode의 경우)에 해당할 수 있습니다. Claude의 경우, 토큰은 대략 3.5개의 영어 문자를 나타내지만, 정확한 수는 사용되는 언어에 따라 달라질 수 있습니다. 토큰은 일반적으로 "텍스트" 수준에서 언어 모델과 상호작용할 때는 숨겨져 있지만, 언어 모델의 정확한 입력과 출력을 검토할 때 관련이 있습니다. Claude에게 평가할 텍스트가 제공되면, 텍스트(일련의 문자로 구성)는 모델이 처리할 수 있도록 일련의 토큰으로 인코딩됩니다. 더 큰 토큰은 추론과 사전훈련 중 데이터 효율성을 가능하게 하며(가능할 때 활용됩니다), 더 작은 토큰은 모델이 흔하지 않거나 이전에 본 적이 없는 단어를 처리할 수 있게 합니다. 토큰화 방법의 선택은 모델의 성능, 어휘 크기, 어휘에 없는 단어를 처리하는 능력에 영향을 줄 수 있습니다.