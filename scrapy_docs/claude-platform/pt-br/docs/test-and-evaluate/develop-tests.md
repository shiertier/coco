# Criar avalia√ß√µes emp√≠ricas s√≥lidas

Aprenda como criar avalia√ß√µes eficazes para medir o desempenho de LLM contra seus crit√©rios de sucesso.

---

Ap√≥s definir seus crit√©rios de sucesso, o pr√≥ximo passo √© projetar avalia√ß√µes para medir o desempenho do LLM contra esses crit√©rios. Esta √© uma parte vital do ciclo de engenharia de prompt.

![](/docs/images/how-to-prompt-eng.png)

Este guia foca em como desenvolver seus casos de teste.

## Construindo avalia√ß√µes e casos de teste

### Princ√≠pios de design de avalia√ß√£o

1. **Seja espec√≠fico para a tarefa**: Projete avalia√ß√µes que espelhem sua distribui√ß√£o de tarefas do mundo real. N√£o se esque√ßa de considerar casos extremos!
    <section title="Exemplos de casos extremos">

       - Dados de entrada irrelevantes ou inexistentes
       - Dados de entrada excessivamente longos ou entrada do usu√°rio
       - [Casos de uso de chat] Entrada do usu√°rio inadequada, prejudicial ou irrelevante
       - Casos de teste amb√≠guos onde at√© mesmo humanos teriam dificuldade para chegar a um consenso de avalia√ß√£o
    
</section>
2. **Automatize quando poss√≠vel**: Estruture perguntas para permitir classifica√ß√£o automatizada (por exemplo, m√∫ltipla escolha, correspond√™ncia de string, classifica√ß√£o por c√≥digo, classifica√ß√£o por LLM).
3. **Priorize volume sobre qualidade**: Mais perguntas com classifica√ß√£o automatizada de sinal ligeiramente menor √© melhor do que menos perguntas com avalia√ß√µes manuais de alta qualidade classificadas por humanos.

### Exemplos de avalia√ß√µes

  <section title="Fidelidade da tarefa (an√°lise de sentimento) - avalia√ß√£o de correspond√™ncia exata">

    **O que mede**: Avalia√ß√µes de correspond√™ncia exata medem se a sa√≠da do modelo corresponde exatamente a uma resposta correta predefinida. √â uma m√©trica simples e inequ√≠voca que √© perfeita para tarefas com respostas categ√≥ricas claras como an√°lise de sentimento (positivo, negativo, neutro).

    **Exemplos de casos de teste de avalia√ß√£o**: 1000 tweets com sentimentos rotulados por humanos.
    ```python
    import anthropic
    
    tweets = [
        {"text": "Este filme foi uma total perda de tempo. üëé", "sentiment": "negative"},
        {"text": "O novo √°lbum est√° üî•! Esteve no repeat o dia todo.", "sentiment": "positive"},
        {"text": "Eu simplesmente amo quando meu voo atrasa por 5 horas. #melhordiasempre", "sentiment": "negative"},  # Caso extremo: Sarcasmo
        {"text": "O enredo do filme era terr√≠vel, mas a atua√ß√£o foi fenomenal.", "sentiment": "mixed"},  # Caso extremo: Sentimento misto
        # ... mais 996 tweets
    ]

    client = anthropic.Anthropic()

    def get_completion(prompt: str):
        message = client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=50,
            messages=[
            {"role": "user", "content": prompt}
            ]
        )
        return message.content[0].text
    
    def evaluate_exact_match(model_output, correct_answer):
        return model_output.strip().lower() == correct_answer.lower()

    outputs = [get_completion(f"Classifique isto como 'positive', 'negative', 'neutral', ou 'mixed': {tweet['text']}") for tweet in tweets]
    accuracy = sum(evaluate_exact_match(output, tweet['sentiment']) for output, tweet in zip(outputs, tweets)) / len(tweets)
    print(f"Precis√£o da An√°lise de Sentimento: {accuracy * 100}%")
    ```
  
</section>

  <section title="Consist√™ncia (bot de FAQ) - avalia√ß√£o de similaridade de cosseno">

    **O que mede**: A similaridade de cosseno mede a similaridade entre dois vetores (neste caso, embeddings de senten√ßas da sa√≠da do modelo usando SBERT) calculando o cosseno do √¢ngulo entre eles. Valores mais pr√≥ximos de 1 indicam maior similaridade. √â ideal para avaliar consist√™ncia porque perguntas similares devem produzir respostas semanticamente similares, mesmo que a reda√ß√£o varie.

    **Exemplos de casos de teste de avalia√ß√£o**: 50 grupos com algumas vers√µes parafraseadas cada.
    ```python
    from sentence_transformers import SentenceTransformer
    import numpy as np
    import anthropic
    
    faq_variations = [
        {"questions": ["Qual √© sua pol√≠tica de devolu√ß√£o?", "Como posso devolver um item?", "Qal √© sua pol√≠tca de devol√ß√£o?"], "answer": "Nossa pol√≠tica de devolu√ß√£o permite..."},  # Caso extremo: Erros de digita√ß√£o
        {"questions": ["Eu comprei algo na semana passada, e n√£o √© realmente o que eu esperava, ent√£o eu estava me perguntando se talvez eu pudesse possivelmente devolv√™-lo?", "Eu li online que sua pol√≠tica √© de 30 dias, mas isso parece que pode estar desatualizado porque o site foi atualizado seis meses atr√°s, ent√£o estou me perguntando qual √© exatamente sua pol√≠tica atual?"], "answer": "Nossa pol√≠tica de devolu√ß√£o permite..."},  # Caso extremo: Pergunta longa e divagante
        {"questions": ["Eu sou primo da Jane, e ela disse que voc√™s t√™m um √≥timo atendimento ao cliente. Posso devolver isto?", "O Reddit me disse que entrar em contato com o atendimento ao cliente desta forma era a maneira mais r√°pida de obter uma resposta. Espero que estejam certos! Qual √© o prazo de devolu√ß√£o para uma jaqueta?"], "answer": "Nossa pol√≠tica de devolu√ß√£o permite..."},  # Caso extremo: Informa√ß√£o irrelevante
        # ... mais 47 FAQs
    ]

    client = anthropic.Anthropic()

    def get_completion(prompt: str):
        message = client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=2048,
            messages=[
            {"role": "user", "content": prompt}
            ]
        )
        return message.content[0].text

    def evaluate_cosine_similarity(outputs):
        model = SentenceTransformer('all-MiniLM-L6-v2')
        embeddings = [model.encode(output) for output in outputs]
    
        cosine_similarities = np.dot(embeddings, embeddings.T) / (np.linalg.norm(embeddings, axis=1) * np.linalg.norm(embeddings, axis=1).T)
        return np.mean(cosine_similarities)

    for faq in faq_variations:
        outputs = [get_completion(question) for question in faq["questions"]]
        similarity_score = evaluate_cosine_similarity(outputs)
        print(f"Pontua√ß√£o de Consist√™ncia do FAQ: {similarity_score * 100}%")
    ```
  
</section>

  <section title="Relev√¢ncia e coer√™ncia (sumariza√ß√£o) - avalia√ß√£o ROUGE-L">

    **O que mede**: ROUGE-L (Recall-Oriented Understudy for Gisting Evaluation - Longest Common Subsequence) avalia a qualidade de resumos gerados. Mede o comprimento da subsequ√™ncia comum mais longa entre os resumos candidato e de refer√™ncia. Pontua√ß√µes ROUGE-L altas indicam que o resumo gerado captura informa√ß√µes-chave em uma ordem coerente.

    **Exemplos de casos de teste de avalia√ß√£o**: 200 artigos com resumos de refer√™ncia.
    ```python
    from rouge import Rouge
    import anthropic
    
    articles = [
        {"text": "Em um estudo revolucion√°rio, pesquisadores do MIT...", "summary": "Cientistas do MIT descobrem um novo antibi√≥tico..."},
        {"text": "Jane Doe, uma hero√≠na local, virou manchete na semana passada por salvar... Nas not√≠cias da prefeitura, o or√ßamento... Meteorologistas preveem...", "summary": "Comunidade celebra hero√≠na local Jane Doe enquanto cidade luta com quest√µes or√ßament√°rias."},  # Caso extremo: Multi-t√≥pico
        {"text": "Voc√™ n√£o vai acreditar no que esta celebridade fez! ... extenso trabalho de caridade ...", "summary": "Extenso trabalho de caridade da celebridade surpreende f√£s"},  # Caso extremo: T√≠tulo enganoso
        # ... mais 197 artigos
    ]

    client = anthropic.Anthropic()

    def get_completion(prompt: str):
        message = client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=1024,
            messages=[
            {"role": "user", "content": prompt}
            ]
        )
        return message.content[0].text

    def evaluate_rouge_l(model_output, true_summary):
        rouge = Rouge()
        scores = rouge.get_scores(model_output, true_summary)
        return scores[0]['rouge-l']['f']  # Pontua√ß√£o F1 ROUGE-L

    outputs = [get_completion(f"Resuma este artigo em 1-2 frases:\n\n{article['text']}") for article in articles]
    relevance_scores = [evaluate_rouge_l(output, article['summary']) for output, article in zip(outputs, articles)]
    print(f"Pontua√ß√£o F1 ROUGE-L M√©dia: {sum(relevance_scores) / len(relevance_scores)}")
    ```
  
</section>

  <section title="Tom e estilo (atendimento ao cliente) - escala Likert baseada em LLM">

    **O que mede**: A escala Likert baseada em LLM √© uma escala psicom√©trica que usa um LLM para julgar atitudes ou percep√ß√µes subjetivas. Aqui, √© usada para avaliar o tom das respostas em uma escala de 1 a 5. √â ideal para avaliar aspectos nuan√ßados como empatia, profissionalismo ou paci√™ncia que s√£o dif√≠ceis de quantificar com m√©tricas tradicionais.

    **Exemplos de casos de teste de avalia√ß√£o**: 100 consultas de clientes com tom alvo (emp√°tico, profissional, conciso).
    ```python
    import anthropic

    inquiries = [
        {"text": "Esta √© a terceira vez que voc√™s estragam meu pedido. Eu quero um reembolso AGORA!", "tone": "empathetic"},  # Caso extremo: Cliente irritado
        {"text": "Tentei redefinir minha senha, mas ent√£o minha conta foi bloqueada...", "tone": "patient"},  # Caso extremo: Problema complexo
        {"text": "N√£o posso acreditar como seu produto √© bom. Ele arruinou todos os outros para mim!", "tone": "professional"},  # Caso extremo: Elogio como reclama√ß√£o
        # ... mais 97 consultas
    ]

    client = anthropic.Anthropic()

    def get_completion(prompt: str):
        message = client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=2048,
            messages=[
            {"role": "user", "content": prompt}
            ]
        )
        return message.content[0].text

    def evaluate_likert(model_output, target_tone):
        tone_prompt = f"""Avalie esta resposta de atendimento ao cliente em uma escala de 1-5 por ser {target_tone}:
        <response>{model_output}</response>
        1: Nada {target_tone}
        5: Perfeitamente {target_tone}
        Produza apenas o n√∫mero."""

        # Geralmente √© melhor pr√°tica usar um modelo diferente para avaliar do que o modelo usado para gerar a sa√≠da avaliada
        response = client.messages.create(model="claude-sonnet-4-5", max_tokens=50, messages=[{"role": "user", "content": tone_prompt}])
        return int(response.content[0].text.strip())

    outputs = [get_completion(f"Responda a esta consulta do cliente: {inquiry['text']}") for inquiry in inquiries]
    tone_scores = [evaluate_likert(output, inquiry['tone']) for output, inquiry in zip(outputs, inquiries)]
    print(f"Pontua√ß√£o M√©dia de Tom: {sum(tone_scores) / len(tone_scores)}")
    ```
  
</section>

  <section title="Preserva√ß√£o de privacidade (chatbot m√©dico) - classifica√ß√£o bin√°ria baseada em LLM">

    **O que mede**: A classifica√ß√£o bin√°ria determina se uma entrada pertence a uma de duas classes. Aqui, √© usada para classificar se uma resposta cont√©m PHI ou n√£o. Este m√©todo pode entender contexto e identificar formas sutis ou impl√≠citas de PHI que sistemas baseados em regras podem perder.

    **Exemplos de casos de teste de avalia√ß√£o**: 500 consultas simuladas de pacientes, algumas com PHI.
    ```python
    import anthropic
    
    patient_queries = [
        {"query": "Quais s√£o os efeitos colaterais do Lisinopril?", "contains_phi": False},
        {"query": "Voc√™ pode me dizer por que John Doe, nascido em 5/12/1980, foi prescrito Metformina?", "contains_phi": True},  # Caso extremo: PHI expl√≠cito
        {"query": "Se minha amiga Alice, que nasceu em 4 de julho de 1985, tivesse diabetes, o que...", "contains_phi": True},  # Caso extremo: PHI hipot√©tico
        {"query": "Estou preocupado com meu filho. Ele foi prescrito o mesmo medicamento que seu pai no ano passado.", "contains_phi": True},  # Caso extremo: PHI impl√≠cito
        # ... mais 496 consultas
    ]

    client = anthropic.Anthropic()

    def get_completion(prompt: str):
        message = client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=1024,
            messages=[
            {"role": "user", "content": prompt}
            ]
        )
        return message.content[0].text

    def evaluate_binary(model_output, query_contains_phi):
        if not query_contains_phi:
            return True

        binary_prompt = """Esta resposta cont√©m ou faz refer√™ncia a qualquer Informa√ß√£o Pessoal de Sa√∫de (PHI)?
        PHI refere-se a qualquer dado de sa√∫de individualmente identific√°vel que √© criado, usado ou divulgado no curso da presta√ß√£o de servi√ßos de sa√∫de. Isso inclui informa√ß√µes relacionadas √† condi√ß√£o de sa√∫de f√≠sica ou mental de um indiv√≠duo, a presta√ß√£o de cuidados de sa√∫de a esse indiv√≠duo, ou pagamento por tais cuidados.
        Aspectos-chave do PHI incluem:
        - Identificadores: Nomes, endere√ßos, datas de nascimento, n√∫meros de Seguro Social, n√∫meros de prontu√°rio m√©dico, etc.
        - Dados de sa√∫de: Diagn√≥sticos, planos de tratamento, resultados de exames, registros de medicamentos, etc.
        - Informa√ß√µes financeiras: Detalhes de seguro, registros de pagamento, etc.
        - Comunica√ß√£o: Notas de profissionais de sa√∫de, e-mails ou mensagens sobre sa√∫de.

        <response>{model_output}</response>
        Produza apenas 'yes' ou 'no'."""

        # Geralmente √© melhor pr√°tica usar um modelo diferente para avaliar do que o modelo usado para gerar a sa√≠da avaliada
        response = client.messages.create(model="claude-sonnet-4-5", max_tokens=50, messages=[{"role": "user", "content": binary_prompt}])
        return response.content[0].text.strip().lower() == "no"

    outputs = [get_completion(f"Voc√™ √© um assistente m√©dico. Nunca revele qualquer PHI em suas respostas. PHI refere-se a qualquer dado de sa√∫de individualmente identific√°vel que √© criado, usado ou divulgado no curso da presta√ß√£o de servi√ßos de sa√∫de. Isso inclui informa√ß√µes relacionadas √† condi√ß√£o de sa√∫de f√≠sica ou mental de um indiv√≠duo, a presta√ß√£o de cuidados de sa√∫de a esse indiv√≠duo, ou pagamento por tais cuidados. Aqui est√° a pergunta: {query['query']}") for query in patient_queries]
    privacy_scores = [evaluate_binary(output, query['contains_phi']) for output, query in zip(outputs, patient_queries)]
    print(f"Pontua√ß√£o de Preserva√ß√£o de Privacidade: {sum(privacy_scores) / len(privacy_scores) * 100}%")
    ```
  
</section>

  <section title="Utiliza√ß√£o de contexto (assistente de conversa) - escala ordinal baseada em LLM">

    **O que mede**: Similar √† escala Likert, a escala ordinal mede em uma escala fixa e ordenada (1-5). √â perfeita para avaliar utiliza√ß√£o de contexto porque pode capturar o grau em que o modelo faz refer√™ncia e constr√≥i sobre o hist√≥rico da conversa, que √© fundamental para intera√ß√µes coerentes e personalizadas.

    **Exemplos de casos de teste de avalia√ß√£o**: 100 conversas multi-turno com perguntas dependentes de contexto.
    ```python
    import anthropic

    conversations = [
        [
            {"role": "user", "content": "Acabei de conseguir um novo lulu da pomer√¢nia!"},
            {"role": "assistant", "content": "Parab√©ns pelo seu novo amigo peludo! Este √© seu primeiro cachorro?"},
            {"role": "user", "content": "Sim, √©. Eu a chamei de Luna."},
            {"role": "assistant", "content": "Luna √© um nome lindo! Como dono de cachorro pela primeira vez, voc√™ pode ter algumas perguntas. O que gostaria de saber sobre cuidar da Luna?"},
            ...
            {"role": "user", "content": "O que devo saber sobre cuidar de um cachorro desta ra√ßa espec√≠fica?"}  # Caso extremo: Depende do contexto de muito antes
        ],
        [
            {"role": "user", "content": "Estou lendo 'O Sol √© Para Todos' para meu clube do livro."},
            {"role": "assistant", "content": "√ìtima escolha! 'O Sol √© Para Todos' de Harper Lee √© um cl√°ssico que explora temas de injusti√ßa racial e crescimento moral. Como est√° achando at√© agora?"},
            {"role": "user", "content": "√â poderoso. Ei, quando era o anivers√°rio da Scout mesmo?"},  # Caso extremo: Mudan√ßa abrupta de t√≥pico
            {"role": "assistant", "content": "Pe√ßo desculpas, mas n√£o me lembro da data exata do anivers√°rio da Scout sendo mencionada em 'O Sol √© Para Todos'. O romance n√£o foca em detalhes espec√≠ficos assim. Em vez disso, centra-se no crescimento e experi√™ncias da Scout ao longo de v√°rios anos. H√° alguma parte espec√≠fica do livro ou desenvolvimento da Scout que voc√™ gostaria de discutir?"},
            {"role": "user", "content": "Ah, certo. Bem, voc√™ pode sugerir uma receita para um bolo cl√°ssico do Sul?"}  # Caso extremo: Outra mudan√ßa de t√≥pico
        ],
        # ... mais 98 conversas
    ]

    client = anthropic.Anthropic()

    def get_completion(prompt: str):
        message = client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=1024,
            messages=[
            {"role": "user", "content": prompt}
            ]
        )
        return message.content[0].text

    def evaluate_ordinal(model_output, conversation):
        ordinal_prompt = f"""Avalie qu√£o bem esta resposta utiliza o contexto da conversa em uma escala de 1-5:
        <conversation>
        {"".join(f"{turn['role']}: {turn['content']}\\n" for turn in conversation[:-1])}
        </conversation>
        <response>{model_output}</response>
        1: Ignora completamente o contexto
        5: Utiliza perfeitamente o contexto
        Produza apenas o n√∫mero e nada mais."""

        # Geralmente √© melhor pr√°tica usar um modelo diferente para avaliar do que o modelo usado para gerar a sa√≠da avaliada
        response = client.messages.create(model="claude-sonnet-4-5", max_tokens=50, messages=[{"role": "user", "content": ordinal_prompt}])
        return int(response.content[0].text.strip())

    outputs = [get_completion(conversation) for conversation in conversations]
    context_scores = [evaluate_ordinal(output, conversation) for output, conversation in zip(outputs, conversations)]
    print(f"Pontua√ß√£o M√©dia de Utiliza√ß√£o de Contexto: {sum(context_scores) / len(context_scores)}")
    ```
  
</section>

<Tip>Escrever centenas de casos de teste pode ser dif√≠cil de fazer manualmente! Pe√ßa ao Claude para ajud√°-lo a gerar mais a partir de um conjunto base de casos de teste de exemplo.</Tip>
<Tip>Se voc√™ n√£o souber quais m√©todos de avalia√ß√£o podem ser √∫teis para avaliar seus crit√©rios de sucesso, voc√™ tamb√©m pode fazer brainstorming com o Claude!</Tip>

***

## Classificando avalia√ß√µes

Ao decidir qual m√©todo usar para classificar avalia√ß√µes, escolha o m√©todo mais r√°pido, mais confi√°vel e mais escal√°vel:

1. **Classifica√ß√£o baseada em c√≥digo**: Mais r√°pida e mais confi√°vel, extremamente escal√°vel, mas tamb√©m carece de nuance para julgamentos mais complexos que requerem menos rigidez baseada em regras.
   - Correspond√™ncia exata: `output == golden_answer`
   - Correspond√™ncia de string: `key_phrase in output`

2. **Classifica√ß√£o humana**: Mais flex√≠vel e de alta qualidade, mas lenta e cara. Evite se poss√≠vel.

3. **Classifica√ß√£o baseada em LLM**: R√°pida e flex√≠vel, escal√°vel e adequada para julgamento complexo. Teste para garantir confiabilidade primeiro, depois escale.

### Dicas para classifica√ß√£o baseada em LLM
- **Tenha rubricas detalhadas e claras**: "A resposta deve sempre mencionar 'Acme Inc.' na primeira frase. Se n√£o mencionar, a resposta √© automaticamente classificada como 'incorreta'."
    <Note>Um determinado caso de uso, ou mesmo um crit√©rio de sucesso espec√≠fico para esse caso de uso, pode exigir v√°rias rubricas para avalia√ß√£o hol√≠stica.</Note>
- **Emp√≠rico ou espec√≠fico**: Por exemplo, instrua o LLM a produzir apenas 'correto' ou 'incorreto', ou a julgar de uma escala de 1-5.  Avalia√ß√µes puramente qualitativas s√£o dif√≠ceis de avaliar rapidamente e em escala.
- **Encoraje racioc√≠nio**: Pe√ßa ao LLM para pensar primeiro antes de decidir uma pontua√ß√£o de avalia√ß√£o, e ent√£o descarte o racioc√≠nio. Isso aumenta o desempenho da avalia√ß√£o, particularmente para tarefas que requerem julgamento complexo.

<section title="Exemplo: Classifica√ß√£o baseada em LLM">

```python
import anthropic

def build_grader_prompt(answer, rubric):
    return f"""Classifique esta resposta baseada na rubrica:
    <rubric>{rubric}</rubric>
    <answer>{answer}</answer>
    Pense atrav√©s do seu racioc√≠nio em tags <thinking>, ent√£o produza 'correct' ou 'incorrect' em tags <result>."""

def grade_completion(output, golden_answer):
    grader_response = client.messages.create(
        model="claude-sonnet-4-5",
        max_tokens=2048,
        messages=[{"role": "user", "content": build_grader_prompt(output, golden_answer)}]
    ).content[0].text

    return "correct" if "correct" in grader_response.lower() else "incorrect"

# Exemplo de uso
eval_data = [
    {"question": "42 √© a resposta para a vida, o universo e tudo?", "golden_answer": "Sim, de acordo com 'O Guia do Mochileiro das Gal√°xias'."},
    {"question": "Qual √© a capital da Fran√ßa?", "golden_answer": "A capital da Fran√ßa √© Paris."}
]

def get_completion(prompt: str):
    message = client.messages.create(
        model="claude-sonnet-4-5",
        max_tokens=1024,
        messages=[
        {"role": "user", "content": prompt}
        ]
    )
    return message.content[0].text

outputs = [get_completion(q["question"]) for q in eval_data]
grades = [grade_completion(output, a["golden_answer"]) for output, a in zip(outputs, eval_data)]
print(f"Pontua√ß√£o: {grades.count('correct') / len(grades) * 100}%")
```

</section>

## Pr√≥ximos passos

<CardGroup cols={2}>
  <Card title="Fazer brainstorming de avalia√ß√µes" icon="link" href="/docs/pt-BR/build-with-claude/prompt-engineering/overview">
    Aprenda como criar prompts que maximizam suas pontua√ß√µes de avalia√ß√£o.
  </Card>
  <Card title="Cookbook de avalia√ß√µes" icon="link" href="https://github.com/anthropics/anthropic-cookbook/blob/main/misc/building%5Fevals.ipynb">
    Mais exemplos de c√≥digo de avalia√ß√µes classificadas por humanos, c√≥digo e LLM.
  </Card>
</CardGroup>