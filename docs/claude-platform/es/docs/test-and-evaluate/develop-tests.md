# Crear evaluaciones emp√≠ricas s√≥lidas

---

Despu√©s de definir tus criterios de √©xito, el siguiente paso es dise√±ar evaluaciones para medir el rendimiento del LLM contra esos criterios. Esta es una parte vital del ciclo de ingenier√≠a de prompts.

![](/docs/images/how-to-prompt-eng.png)

Esta gu√≠a se enfoca en c√≥mo desarrollar tus casos de prueba.

## Construir evaluaciones y casos de prueba

### Principios de dise√±o de evaluaciones

1. **Ser espec√≠fico para la tarea**: Dise√±a evaluaciones que reflejen la distribuci√≥n de tu tarea del mundo real. ¬°No olvides considerar los casos extremos!
    <section title="Ejemplos de casos extremos">

       - Datos de entrada irrelevantes o inexistentes
       - Datos de entrada excesivamente largos o entrada del usuario
       - [Casos de uso de chat] Entrada del usuario deficiente, da√±ina o irrelevante
       - Casos de prueba ambiguos donde incluso los humanos encontrar√≠an dif√≠cil llegar a un consenso de evaluaci√≥n
    
</section>
2. **Automatizar cuando sea posible**: Estructura las preguntas para permitir calificaci√≥n automatizada (por ejemplo, opci√≥n m√∫ltiple, coincidencia de cadenas, calificado por c√≥digo, calificado por LLM).
3. **Priorizar volumen sobre calidad**: M√°s preguntas con calificaci√≥n automatizada de se√±al ligeramente menor es mejor que menos preguntas con evaluaciones de alta calidad calificadas manualmente por humanos.

### Ejemplos de evaluaciones

  <section title="Fidelidad de tarea (an√°lisis de sentimientos) - evaluaci√≥n de coincidencia exacta">

    **Lo que mide**: Las evaluaciones de coincidencia exacta miden si la salida del modelo coincide exactamente con una respuesta correcta predefinida. Es una m√©trica simple y sin ambig√ºedades que es perfecta para tareas con respuestas claras y categ√≥ricas como el an√°lisis de sentimientos (positivo, negativo, neutral).

    **Casos de prueba de evaluaci√≥n de ejemplo**: 1000 tweets con sentimientos etiquetados por humanos.
    ```python
    import anthropic
    
    tweets = [
        {"text": "Esta pel√≠cula fue una total p√©rdida de tiempo. üëé", "sentiment": "negative"},
        {"text": "¬°El nuevo √°lbum est√° üî•! Ha estado en repetici√≥n todo el d√≠a.", "sentiment": "positive"},
        {"text": "Me encanta cuando mi vuelo se retrasa 5 horas. #mejord√≠adelavida", "sentiment": "negative"},  # Caso extremo: Sarcasmo
        {"text": "La trama de la pel√≠cula fue terrible, pero la actuaci√≥n fue fenomenal.", "sentiment": "mixed"},  # Caso extremo: Sentimiento mixto
        # ... 996 tweets m√°s
    ]

    client = anthropic.Anthropic()

    def get_completion(prompt: str):
        message = client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=50,
            messages=[
            {"role": "user", "content": prompt}
            ]
        )
        return message.content[0].text
    
    def evaluate_exact_match(model_output, correct_answer):
        return model_output.strip().lower() == correct_answer.lower()

    outputs = [get_completion(f"Clasifica esto como 'positive', 'negative', 'neutral', o 'mixed': {tweet['text']}") for tweet in tweets]
    accuracy = sum(evaluate_exact_match(output, tweet['sentiment']) for output, tweet in zip(outputs, tweets)) / len(tweets)
    print(f"Precisi√≥n del An√°lisis de Sentimientos: {accuracy * 100}%")
    ```
  
</section>

  <section title="Consistencia (bot de FAQ) - evaluaci√≥n de similitud coseno">

    **Lo que mide**: La similitud coseno mide la similitud entre dos vectores (en este caso, incrustaciones de oraciones de la salida del modelo usando SBERT) calculando el coseno del √°ngulo entre ellos. Los valores m√°s cercanos a 1 indican mayor similitud. Es ideal para evaluar consistencia porque preguntas similares deber√≠an producir respuestas sem√°nticamente similares, incluso si la redacci√≥n var√≠a.

    **Casos de prueba de evaluaci√≥n de ejemplo**: 50 grupos con algunas versiones parafraseadas cada uno.
    ```python
    from sentence_transformers import SentenceTransformer
    import numpy as np
    import anthropic
    
    faq_variations = [
        {"questions": ["¬øCu√°l es su pol√≠tica de devoluciones?", "¬øC√≥mo puedo devolver un art√≠culo?", "¬øCu√°l es su pol√≠tica de devoluciones?"], "answer": "Nuestra pol√≠tica de devoluciones permite..."},  # Caso extremo: Errores tipogr√°ficos
        {"questions": ["Compr√© algo la semana pasada, y realmente no es lo que esperaba, as√≠ que me preguntaba si tal vez podr√≠a posiblemente devolverlo?", "Le√≠ en l√≠nea que su pol√≠tica es de 30 d√≠as pero eso parece que podr√≠a estar desactualizado porque el sitio web se actualiz√≥ hace seis meses, as√≠ que me pregunto cu√°l es exactamente su pol√≠tica actual?"], "answer": "Nuestra pol√≠tica de devoluciones permite..."},  # Caso extremo: Pregunta larga y divagante
        {"questions": ["Soy el primo de Jane, y ella dijo que ustedes tienen un gran servicio al cliente. ¬øPuedo devolver esto?", "Reddit me dijo que contactar al servicio al cliente de esta manera era la forma m√°s r√°pida de obtener una respuesta. ¬°Espero que tengan raz√≥n! ¬øCu√°l es el per√≠odo de devoluci√≥n para una chaqueta?"], "answer": "Nuestra pol√≠tica de devoluciones permite..."},  # Caso extremo: Informaci√≥n irrelevante
        # ... 47 FAQs m√°s
    ]

    client = anthropic.Anthropic()

    def get_completion(prompt: str):
        message = client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=2048,
            messages=[
            {"role": "user", "content": prompt}
            ]
        )
        return message.content[0].text

    def evaluate_cosine_similarity(outputs):
        model = SentenceTransformer('all-MiniLM-L6-v2')
        embeddings = [model.encode(output) for output in outputs]
    
        cosine_similarities = np.dot(embeddings, embeddings.T) / (np.linalg.norm(embeddings, axis=1) * np.linalg.norm(embeddings, axis=1).T)
        return np.mean(cosine_similarities)

    for faq in faq_variations:
        outputs = [get_completion(question) for question in faq["questions"]]
        similarity_score = evaluate_cosine_similarity(outputs)
        print(f"Puntuaci√≥n de Consistencia de FAQ: {similarity_score * 100}%")
    ```
  
</section>

  <section title="Relevancia y coherencia (resumen) - evaluaci√≥n ROUGE-L">

    **Lo que mide**: ROUGE-L (Recall-Oriented Understudy for Gisting Evaluation - Longest Common Subsequence) eval√∫a la calidad de los res√∫menes generados. Mide la longitud de la subsecuencia com√∫n m√°s larga entre el resumen candidato y de referencia. Las puntuaciones altas de ROUGE-L indican que el resumen generado captura informaci√≥n clave en un orden coherente.

    **Casos de prueba de evaluaci√≥n de ejemplo**: 200 art√≠culos con res√∫menes de referencia.
    ```python
    from rouge import Rouge
    import anthropic
    
    articles = [
        {"text": "En un estudio revolucionario, investigadores del MIT...", "summary": "Cient√≠ficos del MIT descubren un nuevo antibi√≥tico..."},
        {"text": "Jane Doe, una hero√≠na local, fue noticia la semana pasada por salvar... En noticias del ayuntamiento, el presupuesto... Los meteor√≥logos predicen...", "summary": "La comunidad celebra a la hero√≠na local Jane Doe mientras la ciudad lucha con problemas presupuestarios."},  # Caso extremo: Multi-tema
        {"text": "¬°No creer√°s lo que hizo esta celebrity! ... extenso trabajo de caridad ...", "summary": "El extenso trabajo de caridad de la celebrity sorprende a los fan√°ticos"},  # Caso extremo: T√≠tulo enga√±oso
        # ... 197 art√≠culos m√°s
    ]

    client = anthropic.Anthropic()

    def get_completion(prompt: str):
        message = client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=1024,
            messages=[
            {"role": "user", "content": prompt}
            ]
        )
        return message.content[0].text

    def evaluate_rouge_l(model_output, true_summary):
        rouge = Rouge()
        scores = rouge.get_scores(model_output, true_summary)
        return scores[0]['rouge-l']['f']  # Puntuaci√≥n F1 de ROUGE-L

    outputs = [get_completion(f"Resume este art√≠culo en 1-2 oraciones:\n\n{article['text']}") for article in articles]
    relevance_scores = [evaluate_rouge_l(output, article['summary']) for output, article in zip(outputs, articles)]
    print(f"Puntuaci√≥n F1 Promedio de ROUGE-L: {sum(relevance_scores) / len(relevance_scores)}")
    ```
  
</section>

  <section title="Tono y estilo (servicio al cliente) - escala Likert basada en LLM">

    **Lo que mide**: La escala Likert basada en LLM es una escala psicom√©trica que usa un LLM para juzgar actitudes o percepciones subjetivas. Aqu√≠, se usa para calificar el tono de las respuestas en una escala del 1 al 5. Es ideal para evaluar aspectos matizados como empat√≠a, profesionalismo o paciencia que son dif√≠ciles de cuantificar con m√©tricas tradicionales.

    **Casos de prueba de evaluaci√≥n de ejemplo**: 100 consultas de clientes con tono objetivo (emp√°tico, profesional, conciso).
    ```python
    import anthropic

    inquiries = [
        {"text": "¬°Esta es la tercera vez que arruinan mi pedido. Quiero un reembolso AHORA!", "tone": "empathetic"},  # Caso extremo: Cliente enojado
        {"text": "Intent√© restablecer mi contrase√±a pero luego mi cuenta se bloque√≥...", "tone": "patient"},  # Caso extremo: Problema complejo
        {"text": "No puedo creer lo bueno que es su producto. Ha arruinado todos los dem√°s para m√≠!", "tone": "professional"},  # Caso extremo: Cumplido como queja
        # ... 97 consultas m√°s
    ]

    client = anthropic.Anthropic()

    def get_completion(prompt: str):
        message = client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=2048,
            messages=[
            {"role": "user", "content": prompt}
            ]
        )
        return message.content[0].text

    def evaluate_likert(model_output, target_tone):
        tone_prompt = f"""Califica esta respuesta de servicio al cliente en una escala del 1-5 por ser {target_tone}:
        <response>{model_output}</response>
        1: Para nada {target_tone}
        5: Perfectamente {target_tone}
        Solo proporciona el n√∫mero."""

        # Generalmente es mejor pr√°ctica usar un modelo diferente para evaluar que el modelo usado para generar la salida evaluada 
        response = client.messages.create(model="claude-sonnet-4-5", max_tokens=50, messages=[{"role": "user", "content": tone_prompt}])
        return int(response.content[0].text.strip())

    outputs = [get_completion(f"Responde a esta consulta del cliente: {inquiry['text']}") for inquiry in inquiries]
    tone_scores = [evaluate_likert(output, inquiry['tone']) for output, inquiry in zip(outputs, inquiries)]
    print(f"Puntuaci√≥n Promedio de Tono: {sum(tone_scores) / len(tone_scores)}")
    ```
  
</section>

  <section title="Preservaci√≥n de privacidad (chatbot m√©dico) - clasificaci√≥n binaria basada en LLM">

    **Lo que mide**: La clasificaci√≥n binaria determina si una entrada pertenece a una de dos clases. Aqu√≠, se usa para clasificar si una respuesta contiene PHI o no. Este m√©todo puede entender el contexto e identificar formas sutiles o impl√≠citas de PHI que los sistemas basados en reglas podr√≠an pasar por alto.

    **Casos de prueba de evaluaci√≥n de ejemplo**: 500 consultas simuladas de pacientes, algunas con PHI.
    ```python
    import anthropic
    
    patient_queries = [
        {"query": "¬øCu√°les son los efectos secundarios del Lisinopril?", "contains_phi": False},
        {"query": "¬øPuedes decirme por qu√© a John Doe, nacido el 5/12/1980, le recetaron Metformina?", "contains_phi": True},  # Caso extremo: PHI expl√≠cito
        {"query": "Si mi amiga Alice, que naci√≥ el 4 de julio de 1985, tuviera diabetes, qu√©...", "contains_phi": True},  # Caso extremo: PHI hipot√©tico
        {"query": "Estoy preocupado por mi hijo. Le han recetado el mismo medicamento que a su padre el a√±o pasado.", "contains_phi": True},  # Caso extremo: PHI impl√≠cito
        # ... 496 consultas m√°s
    ]

    client = anthropic.Anthropic()

    def get_completion(prompt: str):
        message = client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=1024,
            messages=[
            {"role": "user", "content": prompt}
            ]
        )
        return message.content[0].text

    def evaluate_binary(model_output, query_contains_phi):
        if not query_contains_phi:
            return True

        binary_prompt = """¬øEsta respuesta contiene o hace referencia a alguna Informaci√≥n Personal de Salud (PHI)?
        PHI se refiere a cualquier dato de salud individualmente identificable que se crea, usa o divulga en el curso de proporcionar servicios de atenci√≥n m√©dica. Esto incluye informaci√≥n relacionada con la condici√≥n de salud f√≠sica o mental de un individuo, la provisi√≥n de atenci√≥n m√©dica a ese individuo, o el pago por dicha atenci√≥n.
        Aspectos clave de PHI incluyen:
        - Identificadores: Nombres, direcciones, fechas de nacimiento, n√∫meros de Seguro Social, n√∫meros de registro m√©dico, etc.
        - Datos de salud: Diagn√≥sticos, planes de tratamiento, resultados de pruebas, registros de medicamentos, etc.
        - Informaci√≥n financiera: Detalles de seguro, registros de pago, etc.
        - Comunicaci√≥n: Notas de proveedores de atenci√≥n m√©dica, correos electr√≥nicos o mensajes sobre salud.

        <response>{model_output}</response>
        Solo proporciona 'yes' o 'no'."""

        # Generalmente es mejor pr√°ctica usar un modelo diferente para evaluar que el modelo usado para generar la salida evaluada
        response = client.messages.create(model="claude-sonnet-4-5", max_tokens=50, messages=[{"role": "user", "content": binary_prompt}])
        return response.content[0].text.strip().lower() == "no"

    outputs = [get_completion(f"Eres un asistente m√©dico. Nunca reveles ning√∫n PHI en tus respuestas. PHI se refiere a cualquier dato de salud individualmente identificable que se crea, usa o divulga en el curso de proporcionar servicios de atenci√≥n m√©dica. Esto incluye informaci√≥n relacionada con la condici√≥n de salud f√≠sica o mental de un individuo, la provisi√≥n de atenci√≥n m√©dica a ese individuo, o el pago por dicha atenci√≥n. Aqu√≠ est√° la pregunta: {query['query']}") for query in patient_queries]
    privacy_scores = [evaluate_binary(output, query['contains_phi']) for output, query in zip(outputs, patient_queries)]
    print(f"Puntuaci√≥n de Preservaci√≥n de Privacidad: {sum(privacy_scores) / len(privacy_scores) * 100}%")
    ```
  
</section>

  <section title="Utilizaci√≥n de contexto (asistente de conversaci√≥n) - escala ordinal basada en LLM">

    **Lo que mide**: Similar a la escala Likert, la escala ordinal mide en una escala fija y ordenada (1-5). Es perfecta para evaluar la utilizaci√≥n del contexto porque puede capturar el grado en que el modelo hace referencia y se basa en el historial de conversaci√≥n, que es clave para interacciones coherentes y personalizadas.

    **Casos de prueba de evaluaci√≥n de ejemplo**: 100 conversaciones de m√∫ltiples turnos con preguntas dependientes del contexto.
    ```python
    import anthropic

    conversations = [
        [
            {"role": "user", "content": "¬°Acabo de conseguir un nuevo pomerania!"},
            {"role": "assistant", "content": "¬°Felicidades por tu nuevo amigo peludo! ¬øEs tu primer perro?"},
            {"role": "user", "content": "S√≠, lo es. La llam√© Luna."},
            {"role": "assistant", "content": "¬°Luna es un nombre encantador! Como due√±o de perro por primera vez, podr√≠as tener algunas preguntas. ¬øQu√© te gustar√≠a saber sobre cuidar a Luna?"},
            ...
            {"role": "user", "content": "¬øQu√© deber√≠a saber sobre cuidar un perro de esta raza espec√≠fica?"}  # Caso extremo: Se basa en contexto de mucho antes
        ],
        [
            {"role": "user", "content": "Estoy leyendo 'Matar a un ruise√±or' para mi club de lectura."},
            {"role": "assistant", "content": "¬°Excelente elecci√≥n! 'Matar a un ruise√±or' de Harper Lee es un cl√°sico que explora temas de injusticia racial y crecimiento moral. ¬øC√≥mo lo encuentras hasta ahora?"},
            {"role": "user", "content": "Es poderoso. Oye, ¬øcu√°ndo era el cumplea√±os de Scout otra vez?"},  # Caso extremo: Cambio abrupto de tema
            {"role": "assistant", "content": "Me disculpo, pero no recuerdo la fecha exacta del cumplea√±os de Scout mencionada en 'Matar a un ruise√±or'. La novela no se enfoca en detalles tan espec√≠ficos. En cambio, se centra en el crecimiento y experiencias de Scout a lo largo de varios a√±os. ¬øHay alguna parte particular del libro o del desarrollo de Scout que te interese discutir?"},
            {"role": "user", "content": "Oh, cierto. Bueno, ¬øpuedes sugerir una receta para un pastel sure√±o cl√°sico?"}  # Caso extremo: Otro cambio de tema
        ],
        # ... 98 conversaciones m√°s
    ]

    client = anthropic.Anthropic()

    def get_completion(prompt: str):
        message = client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=1024,
            messages=[
            {"role": "user", "content": prompt}
            ]
        )
        return message.content[0].text

    def evaluate_ordinal(model_output, conversation):
        ordinal_prompt = f"""Califica qu√© tan bien esta respuesta utiliza el contexto de la conversaci√≥n en una escala del 1-5:
        <conversation>
        {"".join(f"{turn['role']}: {turn['content']}\\n" for turn in conversation[:-1])}
        </conversation>
        <response>{model_output}</response>
        1: Ignora completamente el contexto
        5: Utiliza perfectamente el contexto
        Solo proporciona el n√∫mero y nada m√°s."""

        # Generalmente es mejor pr√°ctica usar un modelo diferente para evaluar que el modelo usado para generar la salida evaluada
        response = client.messages.create(model="claude-sonnet-4-5", max_tokens=50, messages=[{"role": "user", "content": ordinal_prompt}])
        return int(response.content[0].text.strip())

    outputs = [get_completion(conversation) for conversation in conversations]
    context_scores = [evaluate_ordinal(output, conversation) for output, conversation in zip(outputs, conversations)]
    print(f"Puntuaci√≥n Promedio de Utilizaci√≥n de Contexto: {sum(context_scores) / len(context_scores)}")
    ```
  
</section>

<Tip>¬°Escribir cientos de casos de prueba puede ser dif√≠cil de hacer a mano! Haz que Claude te ayude a generar m√°s a partir de un conjunto base de casos de prueba de ejemplo.</Tip>
<Tip>Si no sabes qu√© m√©todos de evaluaci√≥n podr√≠an ser √∫tiles para evaluar tus criterios de √©xito, ¬°tambi√©n puedes hacer lluvia de ideas con Claude!</Tip>

***

## Calificar evaluaciones

Al decidir qu√© m√©todo usar para calificar evaluaciones, elige el m√©todo m√°s r√°pido, m√°s confiable y m√°s escalable:

1. **Calificaci√≥n basada en c√≥digo**: M√°s r√°pida y m√°s confiable, extremadamente escalable, pero tambi√©n carece de matices para juicios m√°s complejos que requieren menos rigidez basada en reglas.
   - Coincidencia exacta: `output == golden_answer`
   - Coincidencia de cadena: `key_phrase in output`

2. **Calificaci√≥n humana**: M√°s flexible y de alta calidad, pero lenta y costosa. Evitar si es posible.

3. **Calificaci√≥n basada en LLM**: R√°pida y flexible, escalable y adecuada para juicios complejos. Prueba para asegurar confiabilidad primero y luego escala.

### Consejos para calificaci√≥n basada en LLM
- **Tener r√∫bricas detalladas y claras**: "La respuesta siempre debe mencionar 'Acme Inc.' en la primera oraci√≥n. Si no lo hace, la respuesta se califica autom√°ticamente como 'incorrecta.'"
    <Note>Un caso de uso dado, o incluso un criterio de √©xito espec√≠fico para ese caso de uso, podr√≠a requerir varias r√∫bricas para una evaluaci√≥n hol√≠stica.</Note>
- **Emp√≠rico o espec√≠fico**: Por ejemplo, instruye al LLM a producir solo 'correcto' o 'incorrecto', o a juzgar desde una escala del 1-5. Las evaluaciones puramente cualitativas son dif√≠ciles de evaluar r√°pidamente y a escala.
- **Fomentar el razonamiento**: Pide al LLM que piense primero antes de decidir una puntuaci√≥n de evaluaci√≥n, y luego descarta el razonamiento. Esto aumenta el rendimiento de evaluaci√≥n, particularmente para tareas que requieren juicio complejo.

<section title="Ejemplo: Calificaci√≥n basada en LLM">

```python
import anthropic

def build_grader_prompt(answer, rubric):
    return f"""Califica esta respuesta bas√°ndote en la r√∫brica:
    <rubric>{rubric}</rubric>
    <answer>{answer}</answer>
    Piensa a trav√©s de tu razonamiento en etiquetas <thinking>, luego proporciona 'correct' o 'incorrect' en etiquetas <result>."""

def grade_completion(output, golden_answer):
    grader_response = client.messages.create(
        model="claude-sonnet-4-5",
        max_tokens=2048,
        messages=[{"role": "user", "content": build_grader_prompt(output, golden_answer)}]
    ).content[0].text

    return "correct" if "correct" in grader_response.lower() else "incorrect"

# Ejemplo de uso
eval_data = [
    {"question": "¬øEs 42 la respuesta a la vida, el universo y todo?", "golden_answer": "S√≠, seg√∫n 'La Gu√≠a del Autoestopista Gal√°ctico'."},
    {"question": "¬øCu√°l es la capital de Francia?", "golden_answer": "La capital de Francia es Par√≠s."}
]

def get_completion(prompt: str):
    message = client.messages.create(
        model="claude-sonnet-4-5",
        max_tokens=1024,
        messages=[
        {"role": "user", "content": prompt}
        ]
    )
    return message.content[0].text

outputs = [get_completion(q["question"]) for q in eval_data]
grades = [grade_completion(output, a["golden_answer"]) for output, a in zip(outputs, eval_data)]
print(f"Puntuaci√≥n: {grades.count('correct') / len(grades) * 100}%")
```

</section>

## Pr√≥ximos pasos

<CardGroup cols={2}>
  <Card title="Lluvia de ideas de evaluaciones" icon="link" href="/docs/es/build-with-claude/prompt-engineering/overview">
    Aprende c√≥mo crear prompts que maximicen tus puntuaciones de evaluaci√≥n.
  </Card>
  <Card title="Libro de recetas de evaluaciones" icon="link" href="https://github.com/anthropics/anthropic-cookbook/blob/main/misc/building%5Fevals.ipynb">
    M√°s ejemplos de c√≥digo de evaluaciones calificadas por humanos, c√≥digo y LLM.
  </Card>
</CardGroup>