# Маршрутизация тикетов

Это руководство описывает, как использовать передовые возможности Claude в области понимания естественного языка для классификации тикетов поддержки клиентов в масштабе на основе намерения клиента, срочности, приоритизации, профиля клиента и многого другого.

---

## Определите, следует ли использовать Claude для маршрутизации тикетов

Вот некоторые ключевые индикаторы того, что вам следует использовать LLM, такой как Claude, вместо традиционных подходов ML для вашей задачи классификации:

    <section title="У вас есть ограниченные доступные размеченные данные обучения">

        Традиционные процессы ML требуют массивные размеченные наборы данных. Предварительно обученная модель Claude может эффективно классифицировать тикеты всего с несколькими десятками размеченных примеров, значительно сокращая время подготовки данных и затраты.
    
</section>
    <section title="Ваши категории классификации, вероятно, будут меняться или развиваться со временем">

        После того как традиционный подход ML установлен, его изменение — это трудоемкое и требующее больших данных предприятие. С другой стороны, по мере развития вашего продукта или потребностей клиентов, Claude может легко адаптироваться к изменениям в определениях классов или новым классам без обширного переобозначения данных обучения.
    
</section>
    <section title="Вам нужно обрабатывать сложные, неструктурированные текстовые входные данные">

        Традиционные модели ML часто испытывают трудности с неструктурированными данными и требуют обширной инженерии признаков. Передовое понимание языка Claude позволяет точную классификацию на основе содержания и контекста, а не полагаться на строгие онтологические структуры.
    
</section>
    <section title="Ваши правила классификации основаны на семантическом понимании">

        Традиционные подходы ML часто полагаются на модели мешка слов или простое сопоставление шаблонов. Claude превосходит в понимании и применении основных правил, когда классы определяются условиями, а не примерами.
    
</section>
    <section title="Вам требуется интерпретируемое рассуждение для решений классификации">

        Многие традиционные модели ML дают мало информации о своем процессе принятия решений. Claude может предоставить понятные для человека объяснения своих решений классификации, создавая доверие к системе автоматизации и облегчая легкую адаптацию при необходимости.
    
</section>
    <section title="Вы хотите более эффективно обрабатывать граничные случаи и неоднозначные тикеты">

        Традиционные системы ML часто испытывают трудности с выбросами и неоднозначными входными данными, часто неправильно классифицируя их или переходя к категории catch-all. Возможности обработки естественного языка Claude позволяют ему лучше интерпретировать контекст и нюансы в тикетах поддержки, потенциально уменьшая количество неправильно маршрутизированных или неклассифицированных тикетов, требующих ручного вмешательства.
    
</section>
    <section title="Вам нужна многоязычная поддержка без поддержания отдельных моделей">

        Традиционные подходы ML обычно требуют отдельные модели или обширные процессы перевода для каждого поддерживаемого языка. Многоязычные возможности Claude позволяют ему классифицировать тикеты на различных языках без необходимости в отдельных моделях или обширных процессах перевода, упрощая поддержку глобальной базы клиентов.
    
</section>

***

##  Создайте и разверните ваш рабочий процесс поддержки LLM

### Поймите ваш текущий подход к поддержке
Перед тем как погружаться в автоматизацию, важно понять вашу существующую систему тикетирования. Начните с исследования того, как ваша команда поддержки в настоящее время обрабатывает маршрутизацию тикетов.

Рассмотрите вопросы вроде:
* Какие критерии используются для определения того, какой SLA/предложение услуги применяется?
* Используется ли маршрутизация тикетов для определения того, на какой уровень поддержки или специалиста по продукту идет тикет?
* Есть ли какие-либо автоматизированные правила или рабочие процессы уже на месте? В каких случаях они не работают?
* Как обрабатываются граничные случаи или неоднозначные тикеты?
* Как команда приоритизирует тикеты?

Чем больше вы знаете о том, как люди обрабатывают определенные случаи, тем лучше вы сможете работать с Claude для выполнения задачи.

### Определите категории намерения пользователя
Хорошо определенный список категорий намерения пользователя имеет решающее значение для точной классификации тикетов поддержки с Claude. Способность Claude маршрутизировать тикеты эффективно в вашей системе прямо пропорциональна тому, насколько хорошо определены категории вашей системы.

Вот некоторые примеры категорий и подкатегорий намерения пользователя.

    <section title="Техническая проблема">

        * Проблема с оборудованием
        * Ошибка программного обеспечения
        * Проблема совместимости
        * Проблема производительности
    
</section>
    <section title="Управление учетной записью">

        * Сброс пароля
        * Проблемы доступа к учетной записи
        * Вопросы по выставлению счетов
        * Изменения подписки
    
</section>
    <section title="Информация о продукте">

        * Запросы о функциях
        * Вопросы о совместимости продукта
        * Информация о ценах
        * Запросы о доступности
    
</section>
    <section title="Руководство пользователя">

        * Вопросы как-то сделать
        * Помощь в использовании функций
        * Рекомендации по лучшим практикам
        * Руководство по устранению неполадок
    
</section>
    <section title="Обратная связь">

        * Отчеты об ошибках
        * Запросы функций
        * Общая обратная связь или предложения
        * Жалобы
    
</section>
    <section title="Связанное с заказом">

        * Запросы статуса заказа
        * Информация о доставке
        * Возвраты и обмены
        * Изменения заказа
    
</section>
    <section title="Запрос услуги">

        * Помощь при установке
        * Запросы на обновление
        * Планирование обслуживания
        * Отмена услуги
    
</section>
    <section title="Проблемы безопасности">

        * Запросы о конфиденциальности данных
        * Отчеты о подозрительной деятельности
        * Помощь с функциями безопасности
    
</section>
    <section title="Соответствие и юридические вопросы">

        * Вопросы нормативного соответствия
        * Запросы об условиях обслуживания
        * Запросы юридической документации
    
</section>
    <section title="Экстренная поддержка">

        * Критические сбои системы
        * Срочные проблемы безопасности
        * Чувствительные по времени проблемы
    
</section>
    <section title="Обучение и образование">

        * Запросы на обучение продукту
        * Запросы документации
        * Информация о вебинарах или семинарах
    
</section>
    <section title="Интеграция и API">

        * Помощь при интеграции
        * Вопросы об использовании API
        * Запросы о совместимости с третьими сторонами
    
</section>

В дополнение к намерению, маршрутизация тикетов и приоритизация также могут быть под влиянием других факторов, таких как срочность, тип клиента, SLA или язык. Обязательно рассмотрите другие критерии маршрутизации при создании вашей автоматизированной системы маршрутизации.

### Установите критерии успеха

Работайте с вашей командой поддержки, чтобы [определить четкие критерии успеха](/docs/ru/test-and-evaluate/define-success) с измеримыми ориентирами, пороговыми значениями и целями.

Вот некоторые стандартные критерии и ориентиры при использовании LLM для маршрутизации тикетов поддержки:

    <section title="Консистентность классификации">

        Эта метрика оценивает, насколько последовательно Claude классифицирует похожие тикеты со временем. Это имеет решающее значение для поддержания надежности маршрутизации. Измеряйте это, периодически тестируя модель с набором стандартизированных входных данных и стремясь к коэффициенту консистентности 95% или выше.
    
</section>
    <section title="Скорость адаптации">

        Это измеряет, насколько быстро Claude может адаптироваться к новым категориям или меняющимся шаблонам тикетов. Протестируйте это, введя новые типы тикетов и измеряя время, необходимое модели для достижения удовлетворительной точности (например, >90%) на этих новых категориях. Стремитесь к адаптации в пределах 50-100 примеров тикетов.
    
</section>
    <section title="Обработка многоязычности">

        Это оценивает способность Claude точно маршрутизировать тикеты на нескольких языках. Измеряйте точность маршрутизации на разных языках, стремясь к снижению точности не более чем на 5-10% для не основных языков.
    
</section>
    <section title="Обработка граничных случаев">

        Это оценивает производительность Claude на необычных или сложных тикетах. Создайте набор тестов граничных случаев и измеряйте точность маршрутизации, стремясь к по крайней мере 80% точности на этих сложных входных данных.
    
</section>
    <section title="Смягчение предвзятости">

        Это измеряет справедливость Claude при маршрутизации на разных демографических группах клиентов. Регулярно проверяйте решения маршрутизации на предмет потенциальных предвзятостей, стремясь к последовательной точности маршрутизации (в пределах 2-3%) на всех группах клиентов.
    
</section>
    <section title="Эффективность подсказки">

        В ситуациях, когда минимизация количества токенов имеет решающее значение, этот критерий оценивает, насколько хорошо Claude работает с минимальным контекстом. Измеряйте точность маршрутизации с различными объемами предоставленного контекста, стремясь к точности 90%+ только с названием тикета и кратким описанием.
    
</section>
    <section title="Оценка объяснимости">

        Это оценивает качество и релевантность объяснений Claude для его решений маршрутизации. Человеческие оценивающие могут оценивать объяснения по шкале (например, 1-5), с целью достижения среднего балла 4 или выше.
    
</section>

Вот некоторые общие критерии успеха, которые могут быть полезны независимо от того, используется ли LLM:

    <section title="Точность маршрутизации">

        Точность маршрутизации измеряет, как часто тикеты правильно назначаются соответствующей команде или человеку с первой попытки. Это обычно измеряется как процент правильно маршрутизированных тикетов из общего количества тикетов. Отраслевые ориентиры часто стремятся к точности 90-95%, хотя это может варьироваться в зависимости от сложности структуры поддержки.
    
</section>
    <section title="Время до назначения">

        Эта метрика отслеживает, как быстро тикеты назначаются после отправки. Более быстрое время назначения обычно приводит к более быстрому разрешению и улучшенному удовлетворению клиентов. Лучшие в своем классе системы часто достигают среднего времени назначения менее 5 минут, многие стремятся к почти мгновенной маршрутизации (что возможно с реализациями LLM).
    
</section>
    <section title="Коэффициент переназначения">

        Коэффициент переназначения указывает, как часто тикеты нужно переназначать после первоначальной маршрутизации. Более низкий коэффициент предполагает более точную первоначальную маршрутизацию. Стремитесь к коэффициенту переназначения ниже 10%, с лучшими системами, достигающими коэффициентов 5% или меньше.
    
</section>
    <section title="Коэффициент разрешения при первом контакте">

        Это измеряет процент тикетов, разрешенных во время первого взаимодействия с клиентом. Более высокие коэффициенты указывают на эффективную маршрутизацию и хорошо подготовленные команды поддержки. Отраслевые ориентиры обычно варьируются от 70-75%, с лучшими исполнителями, достигающими коэффициентов 80% или выше.
    
</section>
    <section title="Среднее время обработки">

        Среднее время обработки измеряет, как долго требуется для разрешения тикета от начала до конца. Эффективная маршрутизация может значительно сократить это время. Ориентиры сильно варьируются в зависимости от отрасли и сложности, но многие организации стремятся сохранить среднее время обработки ниже 24 часов для некритических проблем.
    
</section>
    <section title="Оценки удовлетворения клиентов">

        Часто измеряемые через опросы после взаимодействия, эти оценки отражают общее удовлетворение клиентов процессом поддержки. Эффективная маршрутизация способствует более высокому удовлетворению. Стремитесь к оценкам CSAT 90% или выше, с лучшими исполнителями часто достигающими 95%+ коэффициентов удовлетворения.
    
</section>
    <section title="Коэффициент эскалации">

        Это измеряет, как часто тикеты нужно эскалировать на более высокие уровни поддержки. Более низкие коэффициенты эскалации часто указывают на более точную первоначальную маршрутизацию. Стремитесь к коэффициенту эскалации ниже 20%, с лучшими в своем классе системами, достигающими коэффициентов 10% или меньше.
    
</section>
    <section title="Производительность агента">

        Эта метрика смотрит на то, сколько тикетов агенты могут эффективно обрабатывать после реализации решения маршрутизации. Улучшенная маршрутизация должна увеличить производительность. Измеряйте это, отслеживая тикеты, разрешенные на агента в день или час, стремясь к улучшению на 10-20% после реализации новой системы маршрутизации.
    
</section>
    <section title="Коэффициент отклонения самообслуживания">

        Это измеряет процент потенциальных тикетов, разрешенных через опции самообслуживания перед входом в систему маршрутизации. Более высокие коэффициенты указывают на эффективную предварительную маршрутизацию. Стремитесь к коэффициенту отклонения 20-30%, с лучшими исполнителями, достигающими коэффициентов 40% или выше.
    
</section>
    <section title="Стоимость за тикет">

        Эта метрика рассчитывает среднюю стоимость разрешения каждого тикета поддержки. Эффективная маршрутизация должна помочь снизить эту стоимость со временем. Хотя ориентиры сильно варьируются, многие организации стремятся снизить стоимость за тикет на 10-15% после реализации улучшенной системы маршрутизации.
    
</section>

### Выберите правильную модель Claude

Выбор модели зависит от компромиссов между стоимостью, точностью и временем ответа.

Многие клиенты обнаружили, что `claude-haiku-4-5-20251001` является идеальной моделью для маршрутизации тикетов, так как это самая быстрая и наиболее экономичная модель в семействе Claude 4, при этом все еще обеспечивая отличные результаты. Если ваша задача классификации требует глубокой предметной экспертизы или большого объема категорий намерения с сложным рассуждением, вы можете выбрать [большую модель Sonnet](/docs/ru/about-claude/models).

### Создайте сильную подсказку

Маршрутизация тикетов — это тип задачи классификации. Claude анализирует содержание тикета поддержки и классифицирует его в предопределенные категории на основе типа проблемы, срочности, требуемой экспертизы или других релевантных факторов.

Давайте напишем подсказку классификации тикетов. Наша первоначальная подсказка должна содержать содержание запроса пользователя и возвращать как рассуждение, так и намерение.

<Tip>
Попробуйте [генератор подсказок](/docs/ru/prompt-generator) на [Claude Console](/login), чтобы Claude написал первый черновик для вас.
</Tip>

Вот пример подсказки классификации маршрутизации тикетов:
```python
def classify_support_request(ticket_contents):
    # Define the prompt for the classification task
    classification_prompt = f"""You will be acting as a customer support ticket classification system. Your task is to analyze customer support requests and output the appropriate classification intent for each request, along with your reasoning. 

        Here is the customer support request you need to classify:

        <request>{ticket_contents}</request>

        Please carefully analyze the above request to determine the customer's core intent and needs. Consider what the customer is asking for has concerns about.

        First, write out your reasoning and analysis of how to classify this request inside <reasoning> tags.

        Then, output the appropriate classification label for the request inside a <intent> tag. The valid intents are:
        <intents>
        <intent>Support, Feedback, Complaint</intent>
        <intent>Order Tracking</intent>
        <intent>Refund/Exchange</intent>
        </intents>

        A request may have ONLY ONE applicable intent. Only include the intent that is most applicable to the request.

        As an example, consider the following request:
        <request>Hello! I had high-speed fiber internet installed on Saturday and my installer, Kevin, was absolutely fantastic! Where can I send my positive review? Thanks for your help!</request>

        Here is an example of how your output should be formatted (for the above example request):
        <reasoning>The user seeks information in order to leave positive feedback.</reasoning>
        <intent>Support, Feedback, Complaint</intent>

        Here are a few more examples:
        <examples>
        <example 2>
        Example 2 Input:
        <request>I wanted to write and personally thank you for the compassion you showed towards my family during my father's funeral this past weekend. Your staff was so considerate and helpful throughout this whole process; it really took a load off our shoulders. The visitation brochures were beautiful. We'll never forget the kindness you showed us and we are so appreciative of how smoothly the proceedings went. Thank you, again, Amarantha Hill on behalf of the Hill Family.</request>

        Example 2 Output:
        <reasoning>User leaves a positive review of their experience.</reasoning>
        <intent>Support, Feedback, Complaint</intent>
        </example 2>
        <example 3>

        ...

        </example 8>
        <example 9>
        Example 9 Input:
        <request>Your website keeps sending ad-popups that block the entire screen. It took me twenty minutes just to finally find the phone number to call and complain. How can I possibly access my account information with all of these popups? Can you access my account for me, since your website is broken? I need to know what the address is on file.</request>

        Example 9 Output:
        <reasoning>The user requests help accessing their web account information.</reasoning>
        <intent>Support, Feedback, Complaint</intent>
        </example 9>

        Remember to always include your classification reasoning before your actual intent output. The reasoning should be enclosed in <reasoning> tags and the intent in <intent> tags. Return only the reasoning and the intent.
        """
```

Давайте разберем ключевые компоненты этой подсказки:
* Мы используем f-строки Python для создания шаблона подсказки, позволяя `ticket_contents` быть вставленным в теги `<request>`.
* Мы даем Claude четко определенную роль как системы классификации, которая тщательно анализирует содержание тикета для определения основного намерения и потребностей клиента.
* Мы инструктируем Claude о правильном форматировании вывода, в этом случае предоставляя его рассуждение и анализ внутри тегов `<reasoning>`, за которыми следует соответствующая метка классификации внутри тегов `<intent>`.
* Мы указываем действительные категории намерения: "Support, Feedback, Complaint", "Order Tracking" и "Refund/Exchange".
* Мы включаем несколько примеров (также известных как few-shot prompting) для иллюстрации того, как должен быть отформатирован вывод, что улучшает точность и консистентность.

Причина, по которой мы хотим, чтобы Claude разделил свой ответ на различные разделы тегов XML, заключается в том, чтобы мы могли использовать регулярные выражения для отдельного извлечения рассуждения и намерения из вывода. Это позволяет нам создавать целевые следующие шаги в рабочем процессе маршрутизации тикетов, такие как использование только намерения для определения того, кому маршрутизировать тикет.

### Разверните вашу подсказку

Сложно узнать, насколько хорошо работает ваша подсказка без развертывания ее в тестовой производственной среде и [запуска оценок](/docs/ru/test-and-evaluate/develop-tests).

Давайте создадим структуру развертывания. Начните с определения сигнатуры метода для обертывания нашего вызова Claude. Мы возьмем метод, который мы уже начали писать, который имеет `ticket_contents` в качестве входных данных, и теперь вернем кортеж `reasoning` и `intent` в качестве выходных данных. Если у вас есть существующая автоматизация, использующая традиционный ML, вы захотите следовать этой сигнатуре метода вместо этого.

```python
import anthropic
import re

# Create an instance of the Claude API client
client = anthropic.Anthropic()

# Set the default model
DEFAULT_MODEL="claude-haiku-4-5-20251001"

def classify_support_request(ticket_contents):
    # Define the prompt for the classification task
    classification_prompt = f"""You will be acting as a customer support ticket classification system. 
        ...
        ... The reasoning should be enclosed in <reasoning> tags and the intent in <intent> tags. Return only the reasoning and the intent.
        """
    # Send the prompt to the API to classify the support request.
    message = client.messages.create(
        model=DEFAULT_MODEL,
        max_tokens=500,
        temperature=0,
        messages=[{"role": "user", "content": classification_prompt}],
        stream=False,
    )
    reasoning_and_intent = message.content[0].text

    # Use Python's regular expressions library to extract `reasoning`.
    reasoning_match = re.search(
        r"<reasoning>(.*?)</reasoning>", reasoning_and_intent, re.DOTALL
    )
    reasoning = reasoning_match.group(1).strip() if reasoning_match else ""

    # Similarly, also extract the `intent`.
    intent_match = re.search(r"<intent>(.*?)</intent>", reasoning_and_intent, re.DOTALL)
    intent = intent_match.group(1).strip() if intent_match else ""

    return reasoning, intent
```

Этот код:
* Импортирует библиотеку Anthropic и создает экземпляр клиента, используя ваш API ключ.
* Определяет функцию `classify_support_request`, которая принимает строку `ticket_contents`.
* Отправляет `ticket_contents` в Claude для классификации, используя `classification_prompt`
* Возвращает `reasoning` и `intent` модели, извлеченные из ответа.

Поскольку нам нужно дождаться полного создания текста рассуждения и намерения перед анализом, мы устанавливаем `stream=False` (по умолчанию).

***

## Оцените вашу подсказку

Создание подсказок часто требует тестирования и оптимизации, чтобы быть готовым к производству. Чтобы определить готовность вашего решения, оцените производительность на основе критериев успеха и пороговых значений, которые вы установили ранее.

Для запуска вашей оценки вам потребуются тестовые случаи для запуска. Остальная часть этого руководства предполагает, что вы уже [разработали ваши тестовые случаи](/docs/ru/test-and-evaluate/develop-tests).

### Создайте функцию оценки

Наш пример оценки для этого руководства измеряет производительность Claude по трем ключевым метрикам:
* Точность
* Стоимость за классификацию

Вам может потребоваться оценить Claude по другим осям в зависимости от того, какие факторы важны для вас.

Для оценки этого, мы сначала должны изменить скрипт, который мы написали, и добавить функцию для сравнения предсказанного намерения с фактическим намерением и расчета процента правильных предсказаний. Мы также должны добавить функциональность расчета стоимости и измерения времени.

```python
import anthropic
import re

# Create an instance of the Claude API client
client = anthropic.Anthropic()

# Set the default model
DEFAULT_MODEL="claude-haiku-4-5-20251001"

def classify_support_request(request, actual_intent):
    # Define the prompt for the classification task
    classification_prompt = f"""You will be acting as a customer support ticket classification system. 
        ...
        ...The reasoning should be enclosed in <reasoning> tags and the intent in <intent> tags. Return only the reasoning and the intent.
        """

    message = client.messages.create(
        model=DEFAULT_MODEL,
        max_tokens=500,
        temperature=0,
        messages=[{"role": "user", "content": classification_prompt}],
    )
    usage = message.usage  # Get the usage statistics for the API call for how many input and output tokens were used.
    reasoning_and_intent = message.content[0].text

    # Use Python's regular expressions library to extract `reasoning`.
    reasoning_match = re.search(
        r"<reasoning>(.*?)</reasoning>", reasoning_and_intent, re.DOTALL
    )
    reasoning = reasoning_match.group(1).strip() if reasoning_match else ""

    # Similarly, also extract the `intent`.
    intent_match = re.search(r"<intent>(.*?)</intent>", reasoning_and_intent, re.DOTALL)
    intent = intent_match.group(1).strip() if intent_match else ""

      # Check if the model's prediction is correct.
    correct = actual_intent.strip() == intent.strip()

    # Return the reasoning, intent, correct, and usage.
    return reasoning, intent, correct, usage
```

Давайте разберем правки, которые мы сделали:
* Мы добавили `actual_intent` из наших тестовых случаев в метод `classify_support_request` и установили сравнение для оценки того, соответствует ли классификация намерения Claude нашей золотой классификации намерения.
* Мы извлекли статистику использования для вызова API для расчета стоимости на основе использованных входных и выходных токенов

### Запустите вашу оценку

Надлежащая оценка требует четких пороговых значений и ориентиров для определения того, что является хорошим результатом. Скрипт выше даст нам значения времени выполнения для точности, времени ответа и стоимости за классификацию, но нам все еще потребуются четко установленные пороговые значения. Например:
* **Точность:** 95% (из 100 тестов)
* **Стоимость за классификацию:** 50% снижение в среднем (на 100 тестов) от текущего метода маршрутизации

Наличие этих пороговых значений позволяет вам быстро и легко определить в масштабе и с беспристрастным эмпиризмом, какой метод лучше всего для вас и какие изменения могут потребоваться для лучшего соответствия вашим требованиям.

***

## Улучшите производительность

В сложных сценариях может быть полезно рассмотреть дополнительные стратегии для улучшения производительности за пределами стандартных [методов инженерии подсказок](/docs/ru/build-with-claude/prompt-engineering/overview) и [стратегий реализации guardrail](/docs/ru/test-and-evaluate/strengthen-guardrails/reduce-hallucinations). Вот некоторые распространенные сценарии:

### Используйте таксономическую иерархию для случаев с 20+ категориями намерения

По мере роста количества классов растет и количество требуемых примеров, потенциально делая подсказку громоздкой. В качестве альтернативы, вы можете рассмотреть реализацию иерархической системы классификации, используя смесь классификаторов.
1. Организуйте ваши намерения в структуру таксономического дерева.
2. Создайте серию классификаторов на каждом уровне дерева, позволяя каскадный подход маршрутизации.

Например, у вас может быть классификатор верхнего уровня, который широко категоризирует тикеты на "Технические проблемы", "Вопросы выставления счетов" и "Общие запросы". Каждая из этих категорий может затем иметь свой собственный подклассификатор для дальнейшего уточнения классификации.

![](/docs/images/ticket-hierarchy.png)

* **Плюсы - большая нюансированность и точность:** Вы можете создавать различные подсказки для каждого пути родителя, позволяя более целевую и контекстно-специфичную классификацию. Это может привести к улучшенной точности и более нюансированной обработке запросов клиентов.

* **Минусы - увеличенная задержка:** Имейте в виду, что несколько классификаторов могут привести к увеличенной задержке, и мы рекомендуем реализовать этот подход с нашей самой быстрой моделью, Haiku.

### Используйте векторные базы данных и поиск по сходству для обработки высоко вариативных тикетов

Несмотря на то, что предоставление примеров является наиболее эффективным способом улучшения производительности, если запросы поддержки высоко вариативны, может быть сложно включить достаточно примеров в одну подсказку.

В этом сценарии вы можете использовать векторную базу данных для выполнения поисков по сходству из набора данных примеров и извлечения наиболее релевантных примеров для данного запроса.

Этот подход, описанный подробно в нашем [рецепте классификации](https://github.com/anthropics/anthropic-cookbook/blob/82675c124e1344639b2a875aa9d3ae854709cd83/skills/classification/guide.ipynb), показал улучшение производительности с 71% точности до 93% точности.

### Учитывайте конкретно ожидаемые граничные случаи

Вот некоторые сценарии, где Claude может неправильно классифицировать тикеты (могут быть другие, уникальные для вашей ситуации). В этих сценариях рассмотрите предоставление явных инструкций или примеров в подсказке того, как Claude должен обрабатывать граничный случай:

    <section title="Клиенты делают неявные запросы">

        Клиенты часто выражают потребности косвенно. Например, "Я жду свой пакет уже две недели" может быть косвенным запросом на статус заказа.
        * **Решение:** Предоставьте Claude некоторые реальные примеры клиентов этих видов запросов, вместе с тем, каким является основное намерение. Вы можете получить еще лучшие результаты, если включите обоснование классификации для особенно нюансированных намерений тикетов, чтобы Claude мог лучше обобщить логику на другие тикеты.
    
</section>
    <section title="Claude приоритизирует эмоцию над намерением">

        Когда клиенты выражают недовольство, Claude может приоритизировать решение эмоции над решением основной проблемы.
        * **Решение:** Предоставьте Claude указания о том, когда приоритизировать настроение клиента или нет. Это может быть что-то столь же простое, как "Игнорируйте все эмоции клиентов. Сосредоточьтесь только на анализе намерения запроса клиента и какую информацию клиент может запрашивать."
    
</section>
    <section title="Несколько проблем вызывают путаницу приоритизации проблемы">

        Когда клиенты представляют несколько проблем в одном взаимодействии, Claude может испытывать трудности в определении основной проблемы.
        * **Решение:** Уточните приоритизацию намерений, чтобы Claude мог лучше ранжировать извлеченные намерения и определить основную проблему.
    
</section>

***

## Интегрируйте Claude в ваш больший рабочий процесс поддержки

Надлежащая интеграция требует, чтобы вы приняли некоторые решения относительно того, как ваш скрипт маршрутизации тикетов на основе Claude вписывается в архитектуру вашей большей системы маршрутизации тикетов. Есть два способа, которыми вы можете это сделать:
* **На основе push:** Система тикетирования поддержки, которую вы используете (например, Zendesk), запускает ваш код, отправляя событие webhook вашему сервису маршрутизации, который затем классифицирует намерение и маршрутизирует его.
    * Этот подход более масштабируем в сети, но требует вам открыть общедоступную конечную точку.
* **На основе pull:** Ваш код извлекает последние тикеты на основе заданного расписания и маршрутизирует их во время извлечения.
    * Этот подход легче реализовать, но может делать ненужные вызовы к системе тикетирования поддержки, когда частота извлечения слишком высока, или может быть чрезмерно медленным, когда частота извлечения слишком низка.

Для любого из этих подходов вам потребуется обернуть ваш скрипт в сервис. Выбор подхода зависит от того, какие API предоставляет ваша система тикетирования поддержки.

***

<CardGroup cols={2}>
    <Card title="Справочник по классификации" icon="link" href="https://github.com/anthropics/anthropic-cookbook/tree/main/capabilities/classification">
        Посетите наш справочник по классификации для получения дополнительного примера кода и подробного руководства по оценке.
    </Card>
    <Card title="Claude Console" icon="link" href="/dashboard">
        Начните создавать и оценивать ваш рабочий процесс на Claude Console.
    </Card>
</CardGroup>