# Контекстные окна

Понимание контекстных окон в Claude и как они работают с расширенным мышлением и использованием инструментов

---

## Понимание контекстного окна

"Контекстное окно" относится ко всему объему текста, на который языковая модель может смотреть назад и ссылаться при генерации нового текста, плюс новый текст, который она генерирует. Это отличается от большого корпуса данных, на которых была обучена языковая модель, и вместо этого представляет "рабочую память" для модели. Большее контекстное окно позволяет модели понимать и отвечать на более сложные и длинные подсказки, в то время как меньшее контекстное окно может ограничить способность модели обрабатывать более длинные подсказки или поддерживать согласованность в расширенных разговорах.

Диаграмма ниже иллюстрирует стандартное поведение контекстного окна для запросов API<sup>1</sup>:

![Диаграмма контекстного окна](/docs/images/context-window.svg)

_<sup>1</sup>Для интерфейсов чата, таких как [claude.ai](https://claude.ai/), контекстные окна также могут быть установлены в системе "первый вошел, первый вышел" на основе скользящего окна._

* **Прогрессивное накопление токенов:** По мере развития разговора через ходы каждое сообщение пользователя и ответ ассистента накапливаются в контекстном окне. Предыдущие ходы полностью сохраняются.
* **Линейный паттерн роста:** Использование контекста растет линейно с каждым ходом, при этом предыдущие ходы полностью сохраняются.
* **Емкость 200K токенов:** Общее доступное контекстное окно (200 000 токенов) представляет максимальную емкость для хранения истории разговора и генерации нового вывода от Claude.
* **Поток ввода-вывода:** Каждый ход состоит из:
  - **Фаза ввода:** Содержит всю предыдущую историю разговора плюс текущее сообщение пользователя
  - **Фаза вывода:** Генерирует текстовый ответ, который становится частью будущего ввода

## Контекстное окно с расширенным мышлением

При использовании [расширенного мышления](/docs/ru/build-with-claude/extended-thinking) все входные и выходные токены, включая токены, используемые для мышления, учитываются в пределе контекстного окна, с несколькими нюансами в многоходовых ситуациях.

Токены бюджета мышления являются подмножеством вашего параметра `max_tokens`, выставляются как выходные токены и учитываются в пределах скорости.

Однако предыдущие блоки мышления автоматически удаляются из расчета контекстного окна API Claude и не являются частью истории разговора, которую модель "видит" для последующих ходов, сохраняя емкость токенов для фактического содержания разговора.

Диаграмма ниже демонстрирует специализированное управление токенами при включении расширенного мышления:

![Диаграмма контекстного окна с расширенным мышлением](/docs/images/context-window-thinking.svg)

* **Удаление расширенного мышления:** Блоки расширенного мышления (показаны темно-серым) генерируются во время фазы вывода каждого хода, **но не переносятся как входные токены для последующих ходов**. Вам не нужно удалять блоки мышления самостоятельно. API Claude делает это автоматически, если вы их передаете.
* **Детали технической реализации:**
  - API автоматически исключает блоки мышления из предыдущих ходов, когда вы передаете их обратно как часть истории разговора.
  - Токены расширенного мышления выставляются как выходные токены только один раз, во время их генерации.
  - Расчет эффективного контекстного окна становится: `context_window = (input_tokens - previous_thinking_tokens) + current_turn_tokens`.
  - Токены мышления включают как блоки `thinking`, так и блоки `redacted_thinking`.

Эта архитектура эффективна по токенам и позволяет проводить обширные рассуждения без потерь токенов, так как блоки мышления могут быть значительной длины.

<Note>
Вы можете прочитать больше о контекстном окне и расширенном мышлении в нашем [руководстве по расширенному мышлению](/docs/ru/build-with-claude/extended-thinking).
</Note>

## Контекстное окно с расширенным мышлением и использованием инструментов

Диаграмма ниже иллюстрирует управление токенами контекстного окна при объединении расширенного мышления с использованием инструментов:

![Диаграмма контекстного окна с расширенным мышлением и использованием инструментов](/docs/images/context-window-thinking-tools.svg)

<Steps>
  <Step title="Архитектура первого хода">
    - **Компоненты ввода:** Конфигурация инструментов и сообщение пользователя
    - **Компоненты вывода:** Расширенное мышление + текстовый ответ + запрос использования инструмента
    - **Расчет токенов:** Все компоненты ввода и вывода учитываются в контекстном окне, и все компоненты вывода выставляются как выходные токены.
  </Step>
  <Step title="Обработка результатов инструмента (ход 2)">
    - **Компоненты ввода:** Каждый блок из первого хода, а также `tool_result`. Блок расширенного мышления **должен** быть возвращен с соответствующими результатами инструмента. Это единственный случай, когда вы **должны** возвращать блоки мышления.
    - **Компоненты вывода:** После того как результаты инструмента переданы обратно в Claude, Claude ответит только текстом (без дополнительного расширенного мышления до следующего сообщения `user`).
    - **Расчет токенов:** Все компоненты ввода и вывода учитываются в контекстном окне, и все компоненты вывода выставляются как выходные токены.
  </Step>
  <Step title="Третий шаг">
    - **Компоненты ввода:** Все входные данные и вывод из предыдущего хода переносятся с исключением блока мышления, который теперь можно удалить, так как Claude завершил весь цикл использования инструмента. API автоматически удалит блок мышления для вас, если вы его передадите, или вы можете удалить его самостоятельно на этом этапе. Это также место, где вы добавили бы следующий ход `User`.
    - **Компоненты вывода:** Поскольку есть новый ход `User` вне цикла использования инструмента, Claude будет генерировать новый блок расширенного мышления и продолжит оттуда.
    - **Расчет токенов:** Токены предыдущего мышления автоматически удаляются из расчетов контекстного окна. Все остальные предыдущие блоки по-прежнему учитываются как часть окна токенов, и блок мышления в текущем ходе `Assistant` учитывается как часть контекстного окна. 
  </Step>
</Steps>

* **Рекомендации для использования инструментов с расширенным мышлением:**
  - При отправке результатов инструмента весь неизмененный блок мышления, который сопровождает этот конкретный запрос инструмента (включая подпись/отредактированные части), должен быть включен.
  - Расчет эффективного контекстного окна для расширенного мышления с использованием инструментов становится: `context_window = input_tokens + current_turn_tokens`.
  - Система использует криптографические подписи для проверки подлинности блока мышления. Невозможность сохранить блоки мышления во время использования инструмента может нарушить непрерывность рассуждений Claude. Таким образом, если вы изменяете блоки мышления, API вернет ошибку.

<Note>
Модели Claude 4 поддерживают [чередующееся мышление](/docs/ru/build-with-claude/extended-thinking#interleaved-thinking), которое позволяет Claude думать между вызовами инструментов и проводить более сложные рассуждения после получения результатов инструмента.

Claude Sonnet 3.7 не поддерживает чередующееся мышление, поэтому нет чередования расширенного мышления и вызовов инструментов без промежуточного хода пользователя, не являющегося `tool_result`.

Для получения дополнительной информации об использовании инструментов с расширенным мышлением см. наше [руководство по расширенному мышлению](/docs/ru/build-with-claude/extended-thinking#extended-thinking-with-tool-use).
</Note>

## Контекстное окно в 1M токенов

Claude Sonnet 4 и 4.5 поддерживают контекстное окно в 1 миллион токенов. Это расширенное контекстное окно позволяет вам обрабатывать намного большие документы, поддерживать более длинные разговоры и работать с более обширными кодовыми базами.

<Note>
Контекстное окно в 1M токенов в настоящее время находится в бета-версии для организаций на [уровне использования](/docs/ru/api/rate-limits) 4 и организаций с пользовательскими ограничениями скорости. Контекстное окно в 1M токенов доступно только для Claude Sonnet 4 и Sonnet 4.5.
</Note>

Чтобы использовать контекстное окно в 1M токенов, включите [бета-заголовок](/docs/ru/api/beta-headers) `context-1m-2025-08-07` в ваши запросы API:

<CodeGroup>

```python Python
from anthropic import Anthropic

client = Anthropic()

response = client.beta.messages.create(
    model="claude-sonnet-4-5",
    max_tokens=1024,
    messages=[
        {"role": "user", "content": "Process this large document..."}
    ],
    betas=["context-1m-2025-08-07"]
)
```

```typescript TypeScript
import Anthropic from '@anthropic-ai/sdk';

const anthropic = new Anthropic();

const msg = await anthropic.beta.messages.create({
  model: 'claude-sonnet-4-5',
  max_tokens: 1024,
  messages: [
    { role: 'user', content: 'Process this large document...' }
  ],
  betas: ['context-1m-2025-08-07']
});
```

```bash cURL
curl https://api.anthropic.com/v1/messages \
  -H "x-api-key: $ANTHROPIC_API_KEY" \
  -H "anthropic-version: 2023-06-01" \
  -H "anthropic-beta: context-1m-2025-08-07" \
  -H "content-type: application/json" \
  -d '{
    "model": "claude-sonnet-4-5",
    "max_tokens": 1024,
    "messages": [
      {"role": "user", "content": "Process this large document..."}
    ]
  }'
```

</CodeGroup>

**Важные рекомендации:**
- **Статус бета-версии**: Это бета-функция, подлежащая изменениям. Функции и цены могут быть изменены или удалены в будущих выпусках.
- **Требование уровня использования**: Контекстное окно в 1M токенов доступно для организаций на [уровне использования](/docs/ru/api/rate-limits) 4 и организаций с пользовательскими ограничениями скорости. Организации более низкого уровня должны перейти на уровень использования 4, чтобы получить доступ к этой функции.
- **Доступность**: Контекстное окно в 1M токенов в настоящее время доступно на Claude API, [Microsoft Foundry](/docs/ru/build-with-claude/claude-in-microsoft-foundry), [Amazon Bedrock](/docs/ru/build-with-claude/claude-on-amazon-bedrock) и [Google Cloud's Vertex AI](/docs/ru/build-with-claude/claude-on-vertex-ai). 
- **Цены**: Запросы, превышающие 200K токенов, автоматически выставляются по премиум-ставкам (2x ввод, 1.5x вывод). Подробнее см. в [документации по ценам](/docs/ru/about-claude/pricing#long-context-pricing).
- **Ограничения скорости**: Запросы с длинным контекстом имеют выделенные ограничения скорости. Подробнее см. в [документации по ограничениям скорости](/docs/ru/api/rate-limits#long-context-rate-limits).
- **Рекомендации для мультимодальности**: При обработке большого количества изображений или PDF-файлов имейте в виду, что файлы могут различаться по использованию токенов. При объединении большой подсказки с большим количеством изображений вы можете достичь [ограничений размера запроса](/docs/ru/api/overview#request-size-limits).

## Осведомленность о контексте в Claude Sonnet 4.5 и Haiku 4.5

Claude Sonnet 4.5 и Claude Haiku 4.5 обладают **осведомленностью о контексте**, позволяя этим моделям отслеживать оставшееся контекстное окно (т.е. "бюджет токенов") на протяжении разговора. Это позволяет Claude более эффективно выполнять задачи и управлять контекстом, понимая, сколько места у него есть для работы. Claude изначально обучен использовать этот контекст именно для того, чтобы продолжить задачу до самого конца, а не угадывать, сколько токенов осталось. Для модели отсутствие осведомленности о контексте похоже на участие в кулинарном шоу без часов. Модели Claude 4.5 меняют это, явно информируя модель об оставшемся контексте, чтобы она могла максимально использовать доступные токены. 

**Как это работает:**

В начале разговора Claude получает информацию об общем контекстном окне:

```
<budget:token_budget>200000</budget:token_budget>
```

Бюджет установлен на 200K токенов (стандартный), 500K токенов (Claude.ai Enterprise) или 1M токенов (бета, для подходящих организаций).

После каждого вызова инструмента Claude получает обновление об оставшейся емкости:

```
<system_warning>Token usage: 35000/200000; 165000 remaining</system_warning>
```

Эта осведомленность помогает Claude определить, сколько емкости остается для работы, и позволяет более эффективно выполнять долгосрочные задачи. Токены изображений включены в эти бюджеты.

**Преимущества:**

Осведомленность о контексте особенно ценна для:
- Долгосрочных сеансов агентов, требующих устойчивого внимания
- Рабочих процессов с несколькими контекстными окнами, где переходы состояния имеют значение
- Сложных задач, требующих тщательного управления токенами

Для рекомендаций по подсказкам по использованию осведомленности о контексте см. наше [руководство по лучшим практикам Claude 4](/docs/ru/build-with-claude/prompt-engineering/claude-4-best-practices#context-awareness-and-multi-window-workflows).

## Управление контекстным окном с новыми моделями Claude

В новых моделях Claude (начиная с Claude Sonnet 3.7), если сумма токенов подсказки и выходных токенов превышает контекстное окно модели, система вернет ошибку валидации вместо молчаливого усечения контекста. Это изменение обеспечивает более предсказуемое поведение, но требует более тщательного управления токенами.

Чтобы спланировать использование токенов и убедиться, что вы остаетесь в пределах контекстного окна, вы можете использовать [API подсчета токенов](/docs/ru/build-with-claude/token-counting) для оценки того, сколько токенов будут использовать ваши сообщения перед отправкой их в Claude.

См. нашу таблицу [сравнения моделей](/docs/ru/about-claude/models/overview#model-comparison-table) для списка размеров контекстного окна по моделям.

# Следующие шаги
<CardGroup cols={2}>
  <Card title="Таблица сравнения моделей" icon="scales" href="/docs/ru/about-claude/models/overview#model-comparison-table">
    См. нашу таблицу сравнения моделей для списка размеров контекстного окна и цен на входные/выходные токены по моделям.
  </Card>
  <Card title="Обзор расширенного мышления" icon="settings" href="/docs/ru/build-with-claude/extended-thinking">
    Узнайте больше о том, как работает расширенное мышление и как его реализовать вместе с другими функциями, такими как использование инструментов и кэширование подсказок.
  </Card>
</CardGroup>