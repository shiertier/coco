---
title: コンテキスト管理
description: Learn how to provide local data via RunContext and expose context to the LLM
---

import { Aside, Code } from '@astrojs/starlight/components';
import localContextExample from '../../../../../../examples/docs/context/localContext.ts?raw';

Context は多義的な用語です。考慮すべきコンテキストには主に 2 つの種類があります:

1. 実行中にコードがアクセスできる **ローカル コンテキスト**: ツールに必要な依存関係やデータ、`onHandoff` のようなコールバック、ライフサイクル フック
2. 応答を生成するときに言語モデルが参照できる **エージェント/LLM のコンテキスト**

## ローカル コンテキスト

ローカル コンテキストは `RunContext<T>` 型で表されます。状態や依存関係を保持する任意のオブジェクトを作成し、それを `Runner.run()` に渡します。すべてのツール呼び出しとフックは `RunContext` ラッパーを受け取り、そのオブジェクトを読み書きできます。

<Code
  lang="typescript"
  code={localContextExample}
  title="ローカル コンテキストの例"
/>

単一の実行に参加するすべてのエージェント、ツール、フックは同じ **型** のコンテキストを使用する必要があります。

ローカル コンテキストの用途:

- 実行に関するデータ（ユーザー名、ID など）
- ロガーやデータ フェッチャーなどの依存関係
- ヘルパー関数

<Aside type="note">
  コンテキスト オブジェクトは LLM
  に送信されません。完全にローカルであり、自由に読み書きできます。
</Aside>

## エージェント/LLM のコンテキスト

LLM が呼び出されるとき、参照できるのは会話履歴に含まれるデータのみです。追加の情報を利用可能にする方法はいくつかあります:

1. エージェントの `instructions` に追加する（system または developer メッセージとも呼ばれます）。これは静的な文字列でも、コンテキストを受け取って文字列を返す関数でも構いません
2. `Runner.run()` を呼び出す際の `input` に含める。これは instructions の手法に似ていますが、メッセージをより低い位置に配置できます（[指揮系統](https://cdn.openai.com/spec/model-spec-2024-05-08.html#follow-the-chain-of-command) 内）
3. 関数ツール経由で公開し、LLM がオンデマンドでデータを取得できるようにする
4. リトリーバルや Web 検索のツールを使用して、ファイル、データベース、または Web からの関連データに基づいて応答を確かなものにする
